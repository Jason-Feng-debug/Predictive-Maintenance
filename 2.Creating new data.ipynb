{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Data\n",
    "\n",
    "**Author: Nagdev Amruthnath**  \n",
    "Most of us have come across situations where we have not enough data for building reliable models due to various reasons such as its expensive to collect data (human studies), limited resources, lack of historical data availability (earth quakes). Even before we begin talking about how to overcome the challange, let me first talk about why we need minimum samples even before we consider building model. First of all we can build a model with low samples. It is defnitly possible! But, the as the number of samples decreases, the margin of error increases and vice versa. If you want to build a model with the highest accuracy you would need a as many samples as possible. There is a formula that can be used to calculate the sample size and is as follows   \n",
    "\n",
    "![Image](https://www.dummies.com/wp-content/uploads/359816.image0.png)  \n",
    "\n",
    "Where, n = sample size\n",
    "       Z = Z-score value\n",
    "       Ïƒ = populated standard deviation\n",
    "       MOE = acceptable margin of error\n",
    "\n",
    "You can also calulated with an online calculator as in this link   \n",
    "https://www.qualtrics.com/blog/calculating-sample-size/  \n",
    "\n",
    "Now we know that why minimum samples are required for achieveing required accuracy, say in same case we do not have an opportunity to collect more samples or available. They we have an option to do the following    \n",
    "1. K-fold cross validation  \n",
    "2. Leave-P-out cross validation  \n",
    "3. Leave-one-out cross validation  \n",
    "4. New data creation through estimation  \n",
    "\n",
    "In K-fold method, the data is split into k partitions and then is trained with each partition and tested with the leftout kth partition. In k-hold method, not all combinations are considered. Only user specified partions are considered. While in leave-one/p-out, all combinations or partitions are cosidered. This is more exhasustive technique in validating the results. The following above two techniques are the most popular techniques that is used both in machine learning and deep learning. \n",
    "\n",
    "In new data creation through estimation technique, rows of missing data is created in the data set and a seperate data imputation model is used to impute missing data in the rows. Multivariate Imputation by Chained Equations (MICE) is one of the most popular algorthims that are available to insert missing data irrespective of data types such as mixes of continuous, binary, unordered categorical and ordered categorical data.\n",
    "\n",
    "There are various tutorials available for k-fold and leave one out models. This tutorial will focus on the fourth model where new data will be created to handle less sample size. In the and a simple classification model with be trained to see if there was a significant imporvement. Also, distribution of imputed and non-imputed data will be compared to see any signifcant difference. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: 'mice'\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    cbind, rbind\n",
      "\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "\n",
    "# load libraies\n",
    "library(mice)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into a dataframe\n",
    "The data availabe in the repository is used for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>time</th><th scope=col>ax</th><th scope=col>ay</th><th scope=col>az</th><th scope=col>aT</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.002  </td><td>-0.3246</td><td> 0.2748</td><td> 0.1502</td><td>0.451  </td><td>1      </td></tr>\n",
       "\t<tr><td>0.009  </td><td> 0.6020</td><td>-0.1900</td><td>-0.3227</td><td>0.709  </td><td>1      </td></tr>\n",
       "\t<tr><td>0.019  </td><td> 0.9787</td><td> 0.3258</td><td> 0.0124</td><td>1.032  </td><td>1      </td></tr>\n",
       "\t<tr><td>0.027  </td><td> 0.6141</td><td>-0.4179</td><td> 0.0471</td><td>0.744  </td><td>1      </td></tr>\n",
       "\t<tr><td>0.038  </td><td>-0.3218</td><td>-0.6389</td><td>-0.4259</td><td>0.833  </td><td>1      </td></tr>\n",
       "\t<tr><td>0.047  </td><td>-0.3607</td><td> 0.1332</td><td>-0.1291</td><td>0.406  </td><td>1      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " time & ax & ay & az & aT & y\\\\\n",
       "\\hline\n",
       "\t 0.002   & -0.3246 &  0.2748 &  0.1502 & 0.451   & 1      \\\\\n",
       "\t 0.009   &  0.6020 & -0.1900 & -0.3227 & 0.709   & 1      \\\\\n",
       "\t 0.019   &  0.9787 &  0.3258 &  0.0124 & 1.032   & 1      \\\\\n",
       "\t 0.027   &  0.6141 & -0.4179 &  0.0471 & 0.744   & 1      \\\\\n",
       "\t 0.038   & -0.3218 & -0.6389 & -0.4259 & 0.833   & 1      \\\\\n",
       "\t 0.047   & -0.3607 &  0.1332 & -0.1291 & 0.406   & 1      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| time | ax | ay | az | aT | y |\n",
       "|---|---|---|---|---|---|\n",
       "| 0.002   | -0.3246 |  0.2748 |  0.1502 | 0.451   | 1       |\n",
       "| 0.009   |  0.6020 | -0.1900 | -0.3227 | 0.709   | 1       |\n",
       "| 0.019   |  0.9787 |  0.3258 |  0.0124 | 1.032   | 1       |\n",
       "| 0.027   |  0.6141 | -0.4179 |  0.0471 | 0.744   | 1       |\n",
       "| 0.038   | -0.3218 | -0.6389 | -0.4259 | 0.833   | 1       |\n",
       "| 0.047   | -0.3607 |  0.1332 | -0.1291 | 0.406   | 1       |\n",
       "\n"
      ],
      "text/plain": [
       "  time  ax      ay      az      aT    y\n",
       "1 0.002 -0.3246  0.2748  0.1502 0.451 1\n",
       "2 0.009  0.6020 -0.1900 -0.3227 0.709 1\n",
       "3 0.019  0.9787  0.3258  0.0124 1.032 1\n",
       "4 0.027  0.6141 -0.4179  0.0471 0.744 1\n",
       "5 0.038 -0.3218 -0.6389 -0.4259 0.833 1\n",
       "6 0.047 -0.3607  0.1332 -0.1291 0.406 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setwd(\"C:/Users/aanamruthn/Documents/Jupyter/Testing/RNotebooksTesting/OpenSourceWork/Experiment\")\n",
    "#read csv files\n",
    "file1 = read.csv(\"dry run.csv\", sep=\",\", header =T)\n",
    "file2 = read.csv(\"base.csv\", sep=\",\", header =T)\n",
    "file3 = read.csv(\"imbalance 1.csv\", sep=\",\", header =T)\n",
    "file4 = read.csv(\"imbalance 2.csv\", sep=\",\", header =T)\n",
    "\n",
    "#Add labels to data\n",
    "file1$y = 1\n",
    "file2$y = 2\n",
    "file3$y = 3\n",
    "file4$y = 4\n",
    "\n",
    "#view top rows of data\n",
    "head(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some features from data\n",
    "the data used in this study is vibration data with different states. The data was collected at 100Hz. The data to be used as is is high dimentional also, we do not have any good summary of the data. Hence, some statistical features are extracted. In this case, sample standard deviation, sample mean, sample min, sample max and sample median is calculated. Also, the  data is aggrigated by 1 second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1$group = as.factor(round(file1$time))\n",
    "file2$group = as.factor(round(file2$time))\n",
    "file3$group = as.factor(round(file3$time))\n",
    "file4$group = as.factor(round(file4$time))\n",
    "#(file1,20)\n",
    "\n",
    "#list of all files\n",
    "files = list(file1, file2, file3, file4)\n",
    "\n",
    "#loop through all files and combine\n",
    "features = NULL\n",
    "for (i in 1:4){\n",
    "res = files[[i]] %>%\n",
    "    group_by(group) %>%\n",
    "    summarize(ax_mean = mean(ax),\n",
    "              ax_sd = sd(ax),\n",
    "              ax_min = min(ax),\n",
    "              ax_max = max(ax),\n",
    "              ax_median = median(ax),\n",
    "              ay_mean = mean(ay),\n",
    "              ay_sd = sd(ay),\n",
    "              ay_min = min(ay),\n",
    "              ay_may = max(ay),\n",
    "              ay_median = median(ay),\n",
    "              az_mean = mean(az),\n",
    "              az_sd = sd(az),\n",
    "              az_min = min(az),\n",
    "              az_maz = max(az),\n",
    "              az_median = median(az),\n",
    "              aT_mean = mean(aT),\n",
    "              aT_sd = sd(aT),\n",
    "              aT_min = min(aT),\n",
    "              aT_maT = max(aT),\n",
    "              aT_median = median(aT),\n",
    "              y = mean(y)\n",
    "             )\n",
    "    features = rbind(features, res)\n",
    "}\n",
    "\n",
    "features = subset(features, select = -group)\n",
    "\n",
    "# store it in a df for future reference\n",
    "actual.features = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study data\n",
    "First, lets look at the size of our populations and summary of our features along with thier data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "362"
      ],
      "text/latex": [
       "362"
      ],
      "text/markdown": [
       "362"
      ],
      "text/plain": [
       "[1] 362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'tbl_df', 'tbl' and 'data.frame':\t362 obs. of  21 variables:\n",
      " $ ax_mean  : num  -0.03816 -0.00581 0.06985 0.01155 0.04669 ...\n",
      " $ ax_sd    : num  0.659 0.633 0.667 0.551 0.643 ...\n",
      " $ ax_min   : num  -1.26 -1.62 -1.46 -1.93 -1.78 ...\n",
      " $ ax_max   : num  1.38 1.19 1.47 1.2 1.48 ...\n",
      " $ ax_median: num  -0.0955 -0.0015 0.107 0.0675 0.0836 ...\n",
      " $ ay_mean  : num  -0.068263 0.003791 0.074433 0.000826 -0.017759 ...\n",
      " $ ay_sd    : num  0.751 0.782 0.802 0.789 0.751 ...\n",
      " $ ay_min   : num  -1.39 -1.56 -1.48 -2 -1.66 ...\n",
      " $ ay_may   : num  1.64 1.54 1.8 1.56 1.44 ...\n",
      " $ ay_median: num  -0.19 0.0101 0.1186 -0.0027 -0.0253 ...\n",
      " $ az_mean  : num  -0.138 -0.205 -0.0641 -0.0929 -0.1399 ...\n",
      " $ az_sd    : num  0.985 0.925 0.929 0.889 0.927 ...\n",
      " $ az_min   : num  -2.68 -3.08 -1.82 -2.16 -1.85 ...\n",
      " $ az_maz   : num  2.75 2.72 2.49 3.24 3.55 ...\n",
      " $ az_median: num  0.0254 -0.2121 -0.1512 -0.1672 -0.1741 ...\n",
      " $ aT_mean  : num  1.27 1.26 1.3 1.2 1.23 ...\n",
      " $ aT_sd    : num  0.583 0.545 0.513 0.513 0.582 ...\n",
      " $ aT_min   : num  0.4 0.41 0.255 0.393 0.313 0.336 0.275 0.196 0.032 0.358 ...\n",
      " $ aT_maT   : num  3.03 3.2 2.64 3.32 3.6 ...\n",
      " $ aT_median: num  1.08 1.14 1.28 1.12 1.17 ...\n",
      " $ y        : num  1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "nrow(features)\n",
    "str(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create observations with NA values in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = features\n",
    "for(i in 363:400){\n",
    "  features1[i,] = NA\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at bottom 50 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ax_mean</th><th scope=col>ax_sd</th><th scope=col>ax_min</th><th scope=col>ax_max</th><th scope=col>ax_median</th><th scope=col>ay_mean</th><th scope=col>ay_sd</th><th scope=col>ay_min</th><th scope=col>ay_may</th><th scope=col>ay_median</th><th scope=col>...</th><th scope=col>az_sd</th><th scope=col>az_min</th><th scope=col>az_maz</th><th scope=col>az_median</th><th scope=col>aT_mean</th><th scope=col>aT_sd</th><th scope=col>aT_min</th><th scope=col>aT_maT</th><th scope=col>aT_median</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.016097030</td><td>0.8938523   </td><td>-2.3445     </td><td>2.3006      </td><td>-0.07360    </td><td>-0.009759406</td><td>1.311817    </td><td>-3.4215     </td><td>2.5028      </td><td> 0.10890    </td><td>...         </td><td>1.264572    </td><td>-2.8751     </td><td>3.3718      </td><td>-0.07070    </td><td>1.866030    </td><td>0.7808319   </td><td>0.380       </td><td>4.098       </td><td>1.8200      </td><td> 4          </td></tr>\n",
       "\t<tr><td>-0.015565347</td><td>0.8956615   </td><td>-2.2661     </td><td>2.5089      </td><td> 0.08640    </td><td> 0.027313861</td><td>1.294063    </td><td>-2.9421     </td><td>2.3497      </td><td> 0.15260    </td><td>...         </td><td>1.368576    </td><td>-3.3165     </td><td>2.6989      </td><td>-0.01660    </td><td>1.930426    </td><td>0.7749686   </td><td>0.127       </td><td>4.463       </td><td>1.8350      </td><td> 4          </td></tr>\n",
       "\t<tr><td> 0.024006250</td><td>0.8653758   </td><td>-2.4099     </td><td>2.5328      </td><td>-0.03170    </td><td> 0.008440625</td><td>1.376398    </td><td>-3.0422     </td><td>2.3727      </td><td> 0.11390    </td><td>...         </td><td>1.449783    </td><td>-4.2171     </td><td>4.7703      </td><td> 0.00110    </td><td>2.003552    </td><td>0.8300253   </td><td>0.387       </td><td>5.138       </td><td>1.9920      </td><td> 4          </td></tr>\n",
       "\t<tr><td>-0.015563000</td><td>0.8720967   </td><td>-2.3451     </td><td>2.3269      </td><td>-0.05325    </td><td> 0.013962000</td><td>1.240091    </td><td>-3.1360     </td><td>2.8563      </td><td> 0.09145    </td><td>...         </td><td>1.418988    </td><td>-3.3758     </td><td>3.4279      </td><td>-0.10410    </td><td>1.895380    </td><td>0.8351505   </td><td>0.173       </td><td>4.458       </td><td>1.8735      </td><td> 4          </td></tr>\n",
       "\t<tr><td> 0.003894898</td><td>0.8806773   </td><td>-2.3098     </td><td>3.1902      </td><td>-0.09260    </td><td> 0.022575510</td><td>1.301955    </td><td>-3.2561     </td><td>2.7833      </td><td>-0.05380    </td><td>...         </td><td>1.271799    </td><td>-3.8035     </td><td>3.1323      </td><td>-0.26115    </td><td>1.852265    </td><td>0.7909640   </td><td>0.436       </td><td>3.944       </td><td>1.7570      </td><td> 4          </td></tr>\n",
       "\t<tr><td>-0.039379208</td><td>0.8127135   </td><td>-2.1523     </td><td>1.8828      </td><td>-0.11250    </td><td> 0.005454455</td><td>1.189519    </td><td>-2.8057     </td><td>2.4852      </td><td> 0.03040    </td><td>...         </td><td>1.366368    </td><td>-3.3928     </td><td>2.4507      </td><td> 0.05430    </td><td>1.828059    </td><td>0.7562042   </td><td>0.580       </td><td>3.573       </td><td>1.6960      </td><td> 4          </td></tr>\n",
       "\t<tr><td> 0.021469000</td><td>0.8272527   </td><td>-1.5895     </td><td>3.7505      </td><td>-0.08995    </td><td> 0.011312000</td><td>1.285206    </td><td>-2.7423     </td><td>2.6785      </td><td>-0.03640    </td><td>...         </td><td>1.177012    </td><td>-2.6649     </td><td>2.1685      </td><td> 0.02755    </td><td>1.785930    </td><td>0.7120829   </td><td>0.298       </td><td>3.895       </td><td>1.7575      </td><td> 4          </td></tr>\n",
       "\t<tr><td> 0.005917000</td><td>0.9139808   </td><td>-2.3310     </td><td>2.8131      </td><td>-0.07800    </td><td>-0.040868000</td><td>1.320873    </td><td>-2.9778     </td><td>2.2841      </td><td>-0.01435    </td><td>...         </td><td>1.401567    </td><td>-3.3728     </td><td>3.3165      </td><td> 0.19485    </td><td>1.947570    </td><td>0.8513573   </td><td>0.397       </td><td>4.191       </td><td>1.8180      </td><td> 4          </td></tr>\n",
       "\t<tr><td>-0.034448571</td><td>0.8640626   </td><td>-2.4917     </td><td>2.4113      </td><td>-0.01960    </td><td>-0.013410476</td><td>1.235196    </td><td>-3.3305     </td><td>2.4912      </td><td> 0.09420    </td><td>...         </td><td>1.327886    </td><td>-2.9864     </td><td>2.8430      </td><td>-0.05300    </td><td>1.882590    </td><td>0.6971337   </td><td>0.370       </td><td>3.775       </td><td>1.9030      </td><td> 4          </td></tr>\n",
       "\t<tr><td> 0.046837374</td><td>0.9776022   </td><td>-1.8688     </td><td>2.6644      </td><td>-0.03600    </td><td> 0.019817172</td><td>1.293644    </td><td>-2.7836     </td><td>2.6166      </td><td> 0.12540    </td><td>...         </td><td>1.245906    </td><td>-2.4813     </td><td>3.2677      </td><td>-0.11460    </td><td>1.901646    </td><td>0.7296095   </td><td>0.283       </td><td>3.813       </td><td>1.8440      </td><td> 4          </td></tr>\n",
       "\t<tr><td>-0.014453061</td><td>0.9553743   </td><td>-2.7118     </td><td>2.4640      </td><td>-0.01000    </td><td>-0.037717347</td><td>1.285358    </td><td>-3.1225     </td><td>2.4506      </td><td> 0.03085    </td><td>...         </td><td>1.457232    </td><td>-4.2512     </td><td>3.3754      </td><td> 0.09325    </td><td>1.984418    </td><td>0.8511168   </td><td>0.446       </td><td>4.351       </td><td>1.8600      </td><td> 4          </td></tr>\n",
       "\t<tr><td> 0.046810870</td><td>0.9259427   </td><td>-1.5309     </td><td>1.9420      </td><td>-0.11455    </td><td> 0.230676087</td><td>1.491983    </td><td>-2.8435     </td><td>2.8405      </td><td> 0.33060    </td><td>...         </td><td>1.111205    </td><td>-2.1748     </td><td>2.9009      </td><td>-0.03790    </td><td>1.927174    </td><td>0.7622031   </td><td>0.491       </td><td>3.355       </td><td>2.1620      </td><td> 4          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "\t<tr><td>          NA</td><td>       NA   </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>          NA</td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>...         </td><td>      NA    </td><td>     NA     </td><td>    NA      </td><td>      NA    </td><td>      NA    </td><td>       NA   </td><td>   NA       </td><td>   NA       </td><td>    NA      </td><td>NA          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       " ax\\_mean & ax\\_sd & ax\\_min & ax\\_max & ax\\_median & ay\\_mean & ay\\_sd & ay\\_min & ay\\_may & ay\\_median & ... & az\\_sd & az\\_min & az\\_maz & az\\_median & aT\\_mean & aT\\_sd & aT\\_min & aT\\_maT & aT\\_median & y\\\\\n",
       "\\hline\n",
       "\t -0.016097030 & 0.8938523    & -2.3445      & 2.3006       & -0.07360     & -0.009759406 & 1.311817     & -3.4215      & 2.5028       &  0.10890     & ...          & 1.264572     & -2.8751      & 3.3718       & -0.07070     & 1.866030     & 0.7808319    & 0.380        & 4.098        & 1.8200       &  4          \\\\\n",
       "\t -0.015565347 & 0.8956615    & -2.2661      & 2.5089       &  0.08640     &  0.027313861 & 1.294063     & -2.9421      & 2.3497       &  0.15260     & ...          & 1.368576     & -3.3165      & 2.6989       & -0.01660     & 1.930426     & 0.7749686    & 0.127        & 4.463        & 1.8350       &  4          \\\\\n",
       "\t  0.024006250 & 0.8653758    & -2.4099      & 2.5328       & -0.03170     &  0.008440625 & 1.376398     & -3.0422      & 2.3727       &  0.11390     & ...          & 1.449783     & -4.2171      & 4.7703       &  0.00110     & 2.003552     & 0.8300253    & 0.387        & 5.138        & 1.9920       &  4          \\\\\n",
       "\t -0.015563000 & 0.8720967    & -2.3451      & 2.3269       & -0.05325     &  0.013962000 & 1.240091     & -3.1360      & 2.8563       &  0.09145     & ...          & 1.418988     & -3.3758      & 3.4279       & -0.10410     & 1.895380     & 0.8351505    & 0.173        & 4.458        & 1.8735       &  4          \\\\\n",
       "\t  0.003894898 & 0.8806773    & -2.3098      & 3.1902       & -0.09260     &  0.022575510 & 1.301955     & -3.2561      & 2.7833       & -0.05380     & ...          & 1.271799     & -3.8035      & 3.1323       & -0.26115     & 1.852265     & 0.7909640    & 0.436        & 3.944        & 1.7570       &  4          \\\\\n",
       "\t -0.039379208 & 0.8127135    & -2.1523      & 1.8828       & -0.11250     &  0.005454455 & 1.189519     & -2.8057      & 2.4852       &  0.03040     & ...          & 1.366368     & -3.3928      & 2.4507       &  0.05430     & 1.828059     & 0.7562042    & 0.580        & 3.573        & 1.6960       &  4          \\\\\n",
       "\t  0.021469000 & 0.8272527    & -1.5895      & 3.7505       & -0.08995     &  0.011312000 & 1.285206     & -2.7423      & 2.6785       & -0.03640     & ...          & 1.177012     & -2.6649      & 2.1685       &  0.02755     & 1.785930     & 0.7120829    & 0.298        & 3.895        & 1.7575       &  4          \\\\\n",
       "\t  0.005917000 & 0.9139808    & -2.3310      & 2.8131       & -0.07800     & -0.040868000 & 1.320873     & -2.9778      & 2.2841       & -0.01435     & ...          & 1.401567     & -3.3728      & 3.3165       &  0.19485     & 1.947570     & 0.8513573    & 0.397        & 4.191        & 1.8180       &  4          \\\\\n",
       "\t -0.034448571 & 0.8640626    & -2.4917      & 2.4113       & -0.01960     & -0.013410476 & 1.235196     & -3.3305      & 2.4912       &  0.09420     & ...          & 1.327886     & -2.9864      & 2.8430       & -0.05300     & 1.882590     & 0.6971337    & 0.370        & 3.775        & 1.9030       &  4          \\\\\n",
       "\t  0.046837374 & 0.9776022    & -1.8688      & 2.6644       & -0.03600     &  0.019817172 & 1.293644     & -2.7836      & 2.6166       &  0.12540     & ...          & 1.245906     & -2.4813      & 3.2677       & -0.11460     & 1.901646     & 0.7296095    & 0.283        & 3.813        & 1.8440       &  4          \\\\\n",
       "\t -0.014453061 & 0.9553743    & -2.7118      & 2.4640       & -0.01000     & -0.037717347 & 1.285358     & -3.1225      & 2.4506       &  0.03085     & ...          & 1.457232     & -4.2512      & 3.3754       &  0.09325     & 1.984418     & 0.8511168    & 0.446        & 4.351        & 1.8600       &  4          \\\\\n",
       "\t  0.046810870 & 0.9259427    & -1.5309      & 1.9420       & -0.11455     &  0.230676087 & 1.491983     & -2.8435      & 2.8405       &  0.33060     & ...          & 1.111205     & -2.1748      & 2.9009       & -0.03790     & 1.927174     & 0.7622031    & 0.491        & 3.355        & 2.1620       &  4          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\t           NA &        NA    &      NA      &     NA       &       NA     &           NA &       NA     &      NA      &     NA       &       NA     & ...          &       NA     &      NA      &     NA       &       NA     &       NA     &        NA    &    NA        &    NA        &     NA       & NA          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| ax_mean | ax_sd | ax_min | ax_max | ax_median | ay_mean | ay_sd | ay_min | ay_may | ay_median | ... | az_sd | az_min | az_maz | az_median | aT_mean | aT_sd | aT_min | aT_maT | aT_median | y |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| -0.016097030 | 0.8938523    | -2.3445      | 2.3006       | -0.07360     | -0.009759406 | 1.311817     | -3.4215      | 2.5028       |  0.10890     | ...          | 1.264572     | -2.8751      | 3.3718       | -0.07070     | 1.866030     | 0.7808319    | 0.380        | 4.098        | 1.8200       |  4           |\n",
       "| -0.015565347 | 0.8956615    | -2.2661      | 2.5089       |  0.08640     |  0.027313861 | 1.294063     | -2.9421      | 2.3497       |  0.15260     | ...          | 1.368576     | -3.3165      | 2.6989       | -0.01660     | 1.930426     | 0.7749686    | 0.127        | 4.463        | 1.8350       |  4           |\n",
       "|  0.024006250 | 0.8653758    | -2.4099      | 2.5328       | -0.03170     |  0.008440625 | 1.376398     | -3.0422      | 2.3727       |  0.11390     | ...          | 1.449783     | -4.2171      | 4.7703       |  0.00110     | 2.003552     | 0.8300253    | 0.387        | 5.138        | 1.9920       |  4           |\n",
       "| -0.015563000 | 0.8720967    | -2.3451      | 2.3269       | -0.05325     |  0.013962000 | 1.240091     | -3.1360      | 2.8563       |  0.09145     | ...          | 1.418988     | -3.3758      | 3.4279       | -0.10410     | 1.895380     | 0.8351505    | 0.173        | 4.458        | 1.8735       |  4           |\n",
       "|  0.003894898 | 0.8806773    | -2.3098      | 3.1902       | -0.09260     |  0.022575510 | 1.301955     | -3.2561      | 2.7833       | -0.05380     | ...          | 1.271799     | -3.8035      | 3.1323       | -0.26115     | 1.852265     | 0.7909640    | 0.436        | 3.944        | 1.7570       |  4           |\n",
       "| -0.039379208 | 0.8127135    | -2.1523      | 1.8828       | -0.11250     |  0.005454455 | 1.189519     | -2.8057      | 2.4852       |  0.03040     | ...          | 1.366368     | -3.3928      | 2.4507       |  0.05430     | 1.828059     | 0.7562042    | 0.580        | 3.573        | 1.6960       |  4           |\n",
       "|  0.021469000 | 0.8272527    | -1.5895      | 3.7505       | -0.08995     |  0.011312000 | 1.285206     | -2.7423      | 2.6785       | -0.03640     | ...          | 1.177012     | -2.6649      | 2.1685       |  0.02755     | 1.785930     | 0.7120829    | 0.298        | 3.895        | 1.7575       |  4           |\n",
       "|  0.005917000 | 0.9139808    | -2.3310      | 2.8131       | -0.07800     | -0.040868000 | 1.320873     | -2.9778      | 2.2841       | -0.01435     | ...          | 1.401567     | -3.3728      | 3.3165       |  0.19485     | 1.947570     | 0.8513573    | 0.397        | 4.191        | 1.8180       |  4           |\n",
       "| -0.034448571 | 0.8640626    | -2.4917      | 2.4113       | -0.01960     | -0.013410476 | 1.235196     | -3.3305      | 2.4912       |  0.09420     | ...          | 1.327886     | -2.9864      | 2.8430       | -0.05300     | 1.882590     | 0.6971337    | 0.370        | 3.775        | 1.9030       |  4           |\n",
       "|  0.046837374 | 0.9776022    | -1.8688      | 2.6644       | -0.03600     |  0.019817172 | 1.293644     | -2.7836      | 2.6166       |  0.12540     | ...          | 1.245906     | -2.4813      | 3.2677       | -0.11460     | 1.901646     | 0.7296095    | 0.283        | 3.813        | 1.8440       |  4           |\n",
       "| -0.014453061 | 0.9553743    | -2.7118      | 2.4640       | -0.01000     | -0.037717347 | 1.285358     | -3.1225      | 2.4506       |  0.03085     | ...          | 1.457232     | -4.2512      | 3.3754       |  0.09325     | 1.984418     | 0.8511168    | 0.446        | 4.351        | 1.8600       |  4           |\n",
       "|  0.046810870 | 0.9259427    | -1.5309      | 1.9420       | -0.11455     |  0.230676087 | 1.491983     | -2.8435      | 2.8405       |  0.33060     | ...          | 1.111205     | -2.1748      | 2.9009       | -0.03790     | 1.927174     | 0.7622031    | 0.491        | 3.355        | 2.1620       |  4           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "|           NA |        NA    |      NA      |     NA       |       NA     |           NA |       NA     |      NA      |     NA       |       NA     | ...          |       NA     |      NA      |     NA       |       NA     |       NA     |        NA    |    NA        |    NA        |     NA       | NA           |\n",
       "\n"
      ],
      "text/plain": [
       "   ax_mean      ax_sd     ax_min  ax_max ax_median ay_mean      ay_sd   \n",
       "1  -0.016097030 0.8938523 -2.3445 2.3006 -0.07360  -0.009759406 1.311817\n",
       "2  -0.015565347 0.8956615 -2.2661 2.5089  0.08640   0.027313861 1.294063\n",
       "3   0.024006250 0.8653758 -2.4099 2.5328 -0.03170   0.008440625 1.376398\n",
       "4  -0.015563000 0.8720967 -2.3451 2.3269 -0.05325   0.013962000 1.240091\n",
       "5   0.003894898 0.8806773 -2.3098 3.1902 -0.09260   0.022575510 1.301955\n",
       "6  -0.039379208 0.8127135 -2.1523 1.8828 -0.11250   0.005454455 1.189519\n",
       "7   0.021469000 0.8272527 -1.5895 3.7505 -0.08995   0.011312000 1.285206\n",
       "8   0.005917000 0.9139808 -2.3310 2.8131 -0.07800  -0.040868000 1.320873\n",
       "9  -0.034448571 0.8640626 -2.4917 2.4113 -0.01960  -0.013410476 1.235196\n",
       "10  0.046837374 0.9776022 -1.8688 2.6644 -0.03600   0.019817172 1.293644\n",
       "11 -0.014453061 0.9553743 -2.7118 2.4640 -0.01000  -0.037717347 1.285358\n",
       "12  0.046810870 0.9259427 -1.5309 1.9420 -0.11455   0.230676087 1.491983\n",
       "13           NA        NA      NA     NA       NA            NA       NA\n",
       "14           NA        NA      NA     NA       NA            NA       NA\n",
       "15           NA        NA      NA     NA       NA            NA       NA\n",
       "16           NA        NA      NA     NA       NA            NA       NA\n",
       "17           NA        NA      NA     NA       NA            NA       NA\n",
       "18           NA        NA      NA     NA       NA            NA       NA\n",
       "19           NA        NA      NA     NA       NA            NA       NA\n",
       "20           NA        NA      NA     NA       NA            NA       NA\n",
       "21           NA        NA      NA     NA       NA            NA       NA\n",
       "22           NA        NA      NA     NA       NA            NA       NA\n",
       "23           NA        NA      NA     NA       NA            NA       NA\n",
       "24           NA        NA      NA     NA       NA            NA       NA\n",
       "25           NA        NA      NA     NA       NA            NA       NA\n",
       "26           NA        NA      NA     NA       NA            NA       NA\n",
       "27           NA        NA      NA     NA       NA            NA       NA\n",
       "28           NA        NA      NA     NA       NA            NA       NA\n",
       "29           NA        NA      NA     NA       NA            NA       NA\n",
       "30           NA        NA      NA     NA       NA            NA       NA\n",
       "31           NA        NA      NA     NA       NA            NA       NA\n",
       "32           NA        NA      NA     NA       NA            NA       NA\n",
       "33           NA        NA      NA     NA       NA            NA       NA\n",
       "34           NA        NA      NA     NA       NA            NA       NA\n",
       "35           NA        NA      NA     NA       NA            NA       NA\n",
       "36           NA        NA      NA     NA       NA            NA       NA\n",
       "37           NA        NA      NA     NA       NA            NA       NA\n",
       "38           NA        NA      NA     NA       NA            NA       NA\n",
       "39           NA        NA      NA     NA       NA            NA       NA\n",
       "40           NA        NA      NA     NA       NA            NA       NA\n",
       "41           NA        NA      NA     NA       NA            NA       NA\n",
       "42           NA        NA      NA     NA       NA            NA       NA\n",
       "43           NA        NA      NA     NA       NA            NA       NA\n",
       "44           NA        NA      NA     NA       NA            NA       NA\n",
       "45           NA        NA      NA     NA       NA            NA       NA\n",
       "46           NA        NA      NA     NA       NA            NA       NA\n",
       "47           NA        NA      NA     NA       NA            NA       NA\n",
       "48           NA        NA      NA     NA       NA            NA       NA\n",
       "49           NA        NA      NA     NA       NA            NA       NA\n",
       "50           NA        NA      NA     NA       NA            NA       NA\n",
       "   ay_min  ay_may ay_median ... az_sd    az_min  az_maz az_median aT_mean \n",
       "1  -3.4215 2.5028  0.10890  ... 1.264572 -2.8751 3.3718 -0.07070  1.866030\n",
       "2  -2.9421 2.3497  0.15260  ... 1.368576 -3.3165 2.6989 -0.01660  1.930426\n",
       "3  -3.0422 2.3727  0.11390  ... 1.449783 -4.2171 4.7703  0.00110  2.003552\n",
       "4  -3.1360 2.8563  0.09145  ... 1.418988 -3.3758 3.4279 -0.10410  1.895380\n",
       "5  -3.2561 2.7833 -0.05380  ... 1.271799 -3.8035 3.1323 -0.26115  1.852265\n",
       "6  -2.8057 2.4852  0.03040  ... 1.366368 -3.3928 2.4507  0.05430  1.828059\n",
       "7  -2.7423 2.6785 -0.03640  ... 1.177012 -2.6649 2.1685  0.02755  1.785930\n",
       "8  -2.9778 2.2841 -0.01435  ... 1.401567 -3.3728 3.3165  0.19485  1.947570\n",
       "9  -3.3305 2.4912  0.09420  ... 1.327886 -2.9864 2.8430 -0.05300  1.882590\n",
       "10 -2.7836 2.6166  0.12540  ... 1.245906 -2.4813 3.2677 -0.11460  1.901646\n",
       "11 -3.1225 2.4506  0.03085  ... 1.457232 -4.2512 3.3754  0.09325  1.984418\n",
       "12 -2.8435 2.8405  0.33060  ... 1.111205 -2.1748 2.9009 -0.03790  1.927174\n",
       "13      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "14      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "15      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "16      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "17      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "18      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "19      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "20      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "21      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "22      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "23      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "24      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "25      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "26      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "27      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "28      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "29      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "30      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "31      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "32      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "33      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "34      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "35      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "36      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "37      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "38      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "39      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "40      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "41      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "42      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "43      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "44      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "45      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "46      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "47      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "48      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "49      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "50      NA     NA       NA  ...       NA      NA     NA       NA        NA\n",
       "   aT_sd     aT_min aT_maT aT_median y \n",
       "1  0.7808319 0.380  4.098  1.8200     4\n",
       "2  0.7749686 0.127  4.463  1.8350     4\n",
       "3  0.8300253 0.387  5.138  1.9920     4\n",
       "4  0.8351505 0.173  4.458  1.8735     4\n",
       "5  0.7909640 0.436  3.944  1.7570     4\n",
       "6  0.7562042 0.580  3.573  1.6960     4\n",
       "7  0.7120829 0.298  3.895  1.7575     4\n",
       "8  0.8513573 0.397  4.191  1.8180     4\n",
       "9  0.6971337 0.370  3.775  1.9030     4\n",
       "10 0.7296095 0.283  3.813  1.8440     4\n",
       "11 0.8511168 0.446  4.351  1.8600     4\n",
       "12 0.7622031 0.491  3.355  2.1620     4\n",
       "13        NA    NA     NA      NA    NA\n",
       "14        NA    NA     NA      NA    NA\n",
       "15        NA    NA     NA      NA    NA\n",
       "16        NA    NA     NA      NA    NA\n",
       "17        NA    NA     NA      NA    NA\n",
       "18        NA    NA     NA      NA    NA\n",
       "19        NA    NA     NA      NA    NA\n",
       "20        NA    NA     NA      NA    NA\n",
       "21        NA    NA     NA      NA    NA\n",
       "22        NA    NA     NA      NA    NA\n",
       "23        NA    NA     NA      NA    NA\n",
       "24        NA    NA     NA      NA    NA\n",
       "25        NA    NA     NA      NA    NA\n",
       "26        NA    NA     NA      NA    NA\n",
       "27        NA    NA     NA      NA    NA\n",
       "28        NA    NA     NA      NA    NA\n",
       "29        NA    NA     NA      NA    NA\n",
       "30        NA    NA     NA      NA    NA\n",
       "31        NA    NA     NA      NA    NA\n",
       "32        NA    NA     NA      NA    NA\n",
       "33        NA    NA     NA      NA    NA\n",
       "34        NA    NA     NA      NA    NA\n",
       "35        NA    NA     NA      NA    NA\n",
       "36        NA    NA     NA      NA    NA\n",
       "37        NA    NA     NA      NA    NA\n",
       "38        NA    NA     NA      NA    NA\n",
       "39        NA    NA     NA      NA    NA\n",
       "40        NA    NA     NA      NA    NA\n",
       "41        NA    NA     NA      NA    NA\n",
       "42        NA    NA     NA      NA    NA\n",
       "43        NA    NA     NA      NA    NA\n",
       "44        NA    NA     NA      NA    NA\n",
       "45        NA    NA     NA      NA    NA\n",
       "46        NA    NA     NA      NA    NA\n",
       "47        NA    NA     NA      NA    NA\n",
       "48        NA    NA     NA      NA    NA\n",
       "49        NA    NA     NA      NA    NA\n",
       "50        NA    NA     NA      NA    NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(features1, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NA's with best values using iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_Data = mice(features1, \n",
    "                    m=1, \n",
    "                    maxit = 50, \n",
    "                    method = 'pmm', \n",
    "                    seed = 999, \n",
    "                    printFlag =FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View imputed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>ax_mean</th><th scope=col>ax_sd</th><th scope=col>ax_min</th><th scope=col>ax_max</th><th scope=col>ax_median</th><th scope=col>ay_mean</th><th scope=col>ay_sd</th><th scope=col>ay_min</th><th scope=col>ay_may</th><th scope=col>ay_median</th><th scope=col>...</th><th scope=col>az_sd</th><th scope=col>az_min</th><th scope=col>az_maz</th><th scope=col>az_median</th><th scope=col>aT_mean</th><th scope=col>aT_sd</th><th scope=col>aT_min</th><th scope=col>aT_maT</th><th scope=col>aT_median</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>351</th><td>-0.016097030</td><td>0.8938523   </td><td>-2.3445     </td><td>2.3006      </td><td>-0.07360    </td><td>-0.009759406</td><td>1.3118166   </td><td>-3.4215     </td><td>2.5028      </td><td> 0.10890    </td><td>...         </td><td>1.2645719   </td><td>-2.8751     </td><td>3.3718      </td><td>-0.07070    </td><td>1.8660297   </td><td>0.7808319   </td><td>0.380       </td><td>4.098       </td><td>1.8200      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>352</th><td>-0.015565347</td><td>0.8956615   </td><td>-2.2661     </td><td>2.5089      </td><td> 0.08640    </td><td> 0.027313861</td><td>1.2940627   </td><td>-2.9421     </td><td>2.3497      </td><td> 0.15260    </td><td>...         </td><td>1.3685757   </td><td>-3.3165     </td><td>2.6989      </td><td>-0.01660    </td><td>1.9304257   </td><td>0.7749686   </td><td>0.127       </td><td>4.463       </td><td>1.8350      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>353</th><td> 0.024006250</td><td>0.8653758   </td><td>-2.4099     </td><td>2.5328      </td><td>-0.03170    </td><td> 0.008440625</td><td>1.3763983   </td><td>-3.0422     </td><td>2.3727      </td><td> 0.11390    </td><td>...         </td><td>1.4497833   </td><td>-4.2171     </td><td>4.7703      </td><td> 0.00110    </td><td>2.0035521   </td><td>0.8300253   </td><td>0.387       </td><td>5.138       </td><td>1.9920      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>354</th><td>-0.015563000</td><td>0.8720967   </td><td>-2.3451     </td><td>2.3269      </td><td>-0.05325    </td><td> 0.013962000</td><td>1.2400913   </td><td>-3.1360     </td><td>2.8563      </td><td> 0.09145    </td><td>...         </td><td>1.4189884   </td><td>-3.3758     </td><td>3.4279      </td><td>-0.10410    </td><td>1.8953800   </td><td>0.8351505   </td><td>0.173       </td><td>4.458       </td><td>1.8735      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>355</th><td> 0.003894898</td><td>0.8806773   </td><td>-2.3098     </td><td>3.1902      </td><td>-0.09260    </td><td> 0.022575510</td><td>1.3019546   </td><td>-3.2561     </td><td>2.7833      </td><td>-0.05380    </td><td>...         </td><td>1.2717989   </td><td>-3.8035     </td><td>3.1323      </td><td>-0.26115    </td><td>1.8522653   </td><td>0.7909640   </td><td>0.436       </td><td>3.944       </td><td>1.7570      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>356</th><td>-0.039379208</td><td>0.8127135   </td><td>-2.1523     </td><td>1.8828      </td><td>-0.11250    </td><td> 0.005454455</td><td>1.1895194   </td><td>-2.8057     </td><td>2.4852      </td><td> 0.03040    </td><td>...         </td><td>1.3663678   </td><td>-3.3928     </td><td>2.4507      </td><td> 0.05430    </td><td>1.8280594   </td><td>0.7562042   </td><td>0.580       </td><td>3.573       </td><td>1.6960      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>357</th><td> 0.021469000</td><td>0.8272527   </td><td>-1.5895     </td><td>3.7505      </td><td>-0.08995    </td><td> 0.011312000</td><td>1.2852056   </td><td>-2.7423     </td><td>2.6785      </td><td>-0.03640    </td><td>...         </td><td>1.1770121   </td><td>-2.6649     </td><td>2.1685      </td><td> 0.02755    </td><td>1.7859300   </td><td>0.7120829   </td><td>0.298       </td><td>3.895       </td><td>1.7575      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>358</th><td> 0.005917000</td><td>0.9139808   </td><td>-2.3310     </td><td>2.8131      </td><td>-0.07800    </td><td>-0.040868000</td><td>1.3208731   </td><td>-2.9778     </td><td>2.2841      </td><td>-0.01435    </td><td>...         </td><td>1.4015674   </td><td>-3.3728     </td><td>3.3165      </td><td> 0.19485    </td><td>1.9475700   </td><td>0.8513573   </td><td>0.397       </td><td>4.191       </td><td>1.8180      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>359</th><td>-0.034448571</td><td>0.8640626   </td><td>-2.4917     </td><td>2.4113      </td><td>-0.01960    </td><td>-0.013410476</td><td>1.2351957   </td><td>-3.3305     </td><td>2.4912      </td><td> 0.09420    </td><td>...         </td><td>1.3278861   </td><td>-2.9864     </td><td>2.8430      </td><td>-0.05300    </td><td>1.8825905   </td><td>0.6971337   </td><td>0.370       </td><td>3.775       </td><td>1.9030      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>360</th><td> 0.046837374</td><td>0.9776022   </td><td>-1.8688     </td><td>2.6644      </td><td>-0.03600    </td><td> 0.019817172</td><td>1.2936436   </td><td>-2.7836     </td><td>2.6166      </td><td> 0.12540    </td><td>...         </td><td>1.2459059   </td><td>-2.4813     </td><td>3.2677      </td><td>-0.11460    </td><td>1.9016465   </td><td>0.7296095   </td><td>0.283       </td><td>3.813       </td><td>1.8440      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>361</th><td>-0.014453061</td><td>0.9553743   </td><td>-2.7118     </td><td>2.4640      </td><td>-0.01000    </td><td>-0.037717347</td><td>1.2853576   </td><td>-3.1225     </td><td>2.4506      </td><td> 0.03085    </td><td>...         </td><td>1.4572321   </td><td>-4.2512     </td><td>3.3754      </td><td> 0.09325    </td><td>1.9844184   </td><td>0.8511168   </td><td>0.446       </td><td>4.351       </td><td>1.8600      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>362</th><td> 0.046810870</td><td>0.9259427   </td><td>-1.5309     </td><td>1.9420      </td><td>-0.11455    </td><td> 0.230676087</td><td>1.4919834   </td><td>-2.8435     </td><td>2.8405      </td><td> 0.33060    </td><td>...         </td><td>1.1112049   </td><td>-2.1748     </td><td>2.9009      </td><td>-0.03790    </td><td>1.9271739   </td><td>0.7622031   </td><td>0.491       </td><td>3.355       </td><td>2.1620      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>363</th><td> 0.011238614</td><td>0.8127502   </td><td>-1.9602     </td><td>2.1430      </td><td> 0.00680    </td><td>-0.013367308</td><td>1.3019546   </td><td>-3.0628     </td><td>2.7338      </td><td> 0.00070    </td><td>...         </td><td>1.4534581   </td><td>-4.4325     </td><td>2.9648      </td><td>-0.03520    </td><td>1.9383000   </td><td>0.8526128   </td><td>0.373       </td><td>4.351       </td><td>1.8705      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>364</th><td>-0.009812264</td><td>0.7680463   </td><td>-2.3492     </td><td>1.3919      </td><td> 0.03110    </td><td> 0.013984158</td><td>0.6084791   </td><td>-1.4155     </td><td>0.9273      </td><td> 0.11860    </td><td>...         </td><td>0.9997898   </td><td>-3.0031     </td><td>3.5781      </td><td>-0.25930    </td><td>1.2219510   </td><td>0.6450616   </td><td>0.233       </td><td>3.603       </td><td>1.0730      </td><td>1           </td></tr>\n",
       "\t<tr><th scope=row>365</th><td>-0.026760000</td><td>0.4780558   </td><td>-1.1826     </td><td>0.9934      </td><td> 0.05560    </td><td>-0.035218269</td><td>0.5632648   </td><td>-1.0761     </td><td>1.2307      </td><td>-0.08165    </td><td>...         </td><td>0.7635922   </td><td>-2.3115     </td><td>1.8934      </td><td> 0.03005    </td><td>0.9714200   </td><td>0.4214891   </td><td>0.214       </td><td>2.180       </td><td>0.9265      </td><td>1           </td></tr>\n",
       "\t<tr><th scope=row>366</th><td> 0.029083000</td><td>0.7515921   </td><td>-2.2628     </td><td>2.4640      </td><td>-0.00820    </td><td> 0.011159596</td><td>1.3073606   </td><td>-3.1360     </td><td>2.8527      </td><td> 0.04010    </td><td>...         </td><td>1.4534581   </td><td>-3.6751     </td><td>2.6187      </td><td>-0.22680    </td><td>1.9367549   </td><td>0.7439326   </td><td>0.354       </td><td>4.156       </td><td>1.8450      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>367</th><td> 0.002401000</td><td>0.5641062   </td><td>-1.1533     </td><td>1.4479      </td><td>-0.04215    </td><td> 0.011159596</td><td>1.0358946   </td><td>-1.9856     </td><td>2.9217      </td><td>-0.07040    </td><td>...         </td><td>0.7141977   </td><td>-1.7791     </td><td>1.3013      </td><td>-0.20785    </td><td>1.2607358   </td><td>0.4523664   </td><td>0.376       </td><td>2.106       </td><td>1.2830      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>368</th><td> 0.017670707</td><td>0.4158231   </td><td>-0.9785     </td><td>1.0647      </td><td> 0.07680    </td><td>-0.026719608</td><td>0.4759174   </td><td>-0.9340     </td><td>0.9077      </td><td>-0.03650    </td><td>...         </td><td>0.6919936   </td><td>-1.6094     </td><td>2.0555      </td><td>-0.19365    </td><td>0.8742105   </td><td>0.3962710   </td><td>0.230       </td><td>2.123       </td><td>0.8120      </td><td>1           </td></tr>\n",
       "\t<tr><th scope=row>369</th><td>-0.078038776</td><td>0.4413032   </td><td>-1.1099     </td><td>0.9826      </td><td>-0.03910    </td><td>-0.010626042</td><td>0.4768587   </td><td>-0.9392     </td><td>0.8497      </td><td>-0.04655    </td><td>...         </td><td>0.8165436   </td><td>-2.2936     </td><td>2.1036      </td><td>-0.29570    </td><td>0.9319524   </td><td>0.4517633   </td><td>0.193       </td><td>2.380       </td><td>0.8865      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>370</th><td> 0.004372632</td><td>0.8352791   </td><td>-1.6966     </td><td>2.3897      </td><td> 0.00845    </td><td>-0.010064000</td><td>1.2746954   </td><td>-2.7832     </td><td>2.2841      </td><td> 0.03085    </td><td>...         </td><td>1.2177225   </td><td>-3.1289     </td><td>3.0919      </td><td> 0.01905    </td><td>1.7844653   </td><td>0.7343952   </td><td>0.489       </td><td>3.764       </td><td>1.7520      </td><td>3           </td></tr>\n",
       "\t<tr><th scope=row>371</th><td> 0.016103000</td><td>0.3997476   </td><td>-0.9537     </td><td>1.1546      </td><td> 0.03655    </td><td>-0.031622772</td><td>0.4828770   </td><td>-0.9772     </td><td>1.1237      </td><td>-0.14540    </td><td>...         </td><td>0.7672163   </td><td>-1.9821     </td><td>1.8173      </td><td>-0.09240    </td><td>0.9053800   </td><td>0.4160549   </td><td>0.201       </td><td>2.053       </td><td>0.8520      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>372</th><td>-0.020355446</td><td>0.4178729   </td><td>-1.0524     </td><td>0.9076      </td><td>-0.09340    </td><td> 0.044400000</td><td>0.5439558   </td><td>-0.9843     </td><td>1.0798      </td><td> 0.14000    </td><td>...         </td><td>0.7552593   </td><td>-2.0607     </td><td>1.6134      </td><td>-0.17990    </td><td>0.9498911   </td><td>0.3846176   </td><td>0.222       </td><td>1.752       </td><td>0.8950      </td><td>1           </td></tr>\n",
       "\t<tr><th scope=row>373</th><td> 0.001363636</td><td>0.4868077   </td><td>-0.9027     </td><td>1.5155      </td><td> 0.04820    </td><td> 0.031339000</td><td>1.0619675   </td><td>-2.3261     </td><td>2.4081      </td><td>-0.00210    </td><td>...         </td><td>0.7598489   </td><td>-1.7482     </td><td>1.3013      </td><td>-0.20075    </td><td>1.3272772   </td><td>0.4315494   </td><td>0.478       </td><td>2.288       </td><td>1.3220      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>374</th><td>-0.008122222</td><td>0.8831968   </td><td>-1.9394     </td><td>3.3244      </td><td>-0.09610    </td><td> 0.017400971</td><td>1.3778757   </td><td>-3.7580     </td><td>2.4527      </td><td> 0.16935    </td><td>...         </td><td>1.4260617   </td><td>-3.1893     </td><td>3.5781      </td><td> 0.09325    </td><td>1.9576857   </td><td>0.9167571   </td><td>0.295       </td><td>4.830       </td><td>1.9430      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>375</th><td>-0.065401010</td><td>0.8489219   </td><td>-2.4871     </td><td>2.1672      </td><td>-0.11250    </td><td>-0.043491753</td><td>0.5648206   </td><td>-1.5188     </td><td>0.8497      </td><td> 0.05440    </td><td>...         </td><td>1.4259974   </td><td>-3.1893     </td><td>4.6557      </td><td> 0.08010    </td><td>1.4950297   </td><td>0.8012418   </td><td>0.198       </td><td>4.290       </td><td>1.2550      </td><td>1           </td></tr>\n",
       "\t<tr><th scope=row>376</th><td> 0.039720000</td><td>0.5946125   </td><td>-1.5250     </td><td>1.7390      </td><td> 0.05040    </td><td> 0.061424510</td><td>0.8133879   </td><td>-1.2303     </td><td>1.6255      </td><td> 0.05660    </td><td>...         </td><td>0.9355264   </td><td>-2.2936     </td><td>2.9202      </td><td> 0.02420    </td><td>1.2507900   </td><td>0.5391791   </td><td>0.294       </td><td>3.081       </td><td>1.1770      </td><td>3           </td></tr>\n",
       "\t<tr><th scope=row>377</th><td> 0.022841000</td><td>0.8646867   </td><td>-2.1253     </td><td>2.6378      </td><td> 0.05720    </td><td> 0.052515306</td><td>1.1332836   </td><td>-2.5429     </td><td>2.3692      </td><td> 0.10620    </td><td>...         </td><td>1.0360114   </td><td>-3.0924     </td><td>3.0590      </td><td> 0.00110    </td><td>1.5811275   </td><td>0.7053254   </td><td>0.326       </td><td>3.742       </td><td>1.5815      </td><td>3           </td></tr>\n",
       "\t<tr><th scope=row>378</th><td>-0.001924510</td><td>0.5975310   </td><td>-1.4775     </td><td>1.4089      </td><td>-0.11455    </td><td>-0.040868000</td><td>1.0363392   </td><td>-2.3289     </td><td>2.2123      </td><td> 0.03025    </td><td>...         </td><td>0.7546022   </td><td>-1.6175     </td><td>1.2922      </td><td>-0.18510    </td><td>1.3324845   </td><td>0.5131552   </td><td>0.305       </td><td>2.091       </td><td>1.2830      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>379</th><td> 0.017975000</td><td>0.4780750   </td><td>-1.2011     </td><td>1.4923      </td><td>-0.07450    </td><td>-0.022319802</td><td>0.5072372   </td><td>-1.1404     </td><td>1.0361      </td><td>-0.04135    </td><td>...         </td><td>0.7439169   </td><td>-2.0052     </td><td>1.7066      </td><td>-0.09450    </td><td>0.9151400   </td><td>0.4541700   </td><td>0.262       </td><td>2.264       </td><td>0.8270      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>380</th><td>-0.070804000</td><td>0.4780558   </td><td>-1.9254     </td><td>0.9244      </td><td>-0.05830    </td><td>-0.074927551</td><td>0.5037149   </td><td>-1.0485     </td><td>1.0710      </td><td>-0.07750    </td><td>...         </td><td>0.7598489   </td><td>-2.1735     </td><td>2.0385      </td><td>-0.24560    </td><td>0.9281400   </td><td>0.4813814   </td><td>0.150       </td><td>2.084       </td><td>0.7900      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>381</th><td>-0.002204762</td><td>0.9310547   </td><td>-2.7832     </td><td>2.5242      </td><td>-0.07875    </td><td>-0.019305882</td><td>1.3019546   </td><td>-2.4215     </td><td>2.8615      </td><td>-0.02880    </td><td>...         </td><td>1.1771775   </td><td>-3.0903     </td><td>2.4800      </td><td>-0.19155    </td><td>1.8377451   </td><td>0.7254306   </td><td>0.377       </td><td>3.348       </td><td>1.7770      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>382</th><td> 0.021469000</td><td>0.8646867   </td><td>-2.0001     </td><td>2.4477      </td><td>-0.03400    </td><td> 0.051977895</td><td>1.3628383   </td><td>-2.6574     </td><td>2.7414      </td><td> 0.15305    </td><td>...         </td><td>1.1474602   </td><td>-2.9516     </td><td>2.6371      </td><td> 0.08870    </td><td>1.7884124   </td><td>0.7520192   </td><td>0.400       </td><td>3.651       </td><td>1.9180      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>383</th><td>-0.015468354</td><td>0.8127502   </td><td>-2.2034     </td><td>2.3405      </td><td>-0.02150    </td><td> 0.046179798</td><td>1.3628383   </td><td>-2.8594     </td><td>2.7288      </td><td> 0.02130    </td><td>...         </td><td>1.1112049   </td><td>-4.2171     </td><td>1.7215      </td><td> 0.09600    </td><td>1.7592828   </td><td>0.7680118   </td><td>0.295       </td><td>3.671       </td><td>1.7780      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>384</th><td>-0.002143000</td><td>0.4442709   </td><td>-0.9949     </td><td>1.0734      </td><td>-0.04265    </td><td>-0.007904000</td><td>0.5386439   </td><td>-1.2828     </td><td>1.2250      </td><td>-0.06765    </td><td>...         </td><td>0.7335329   </td><td>-2.2694     </td><td>2.1640      </td><td>-0.30150    </td><td>0.9293627   </td><td>0.4517633   </td><td>0.266       </td><td>2.407       </td><td>0.8000      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>385</th><td> 0.027587129</td><td>0.4551125   </td><td>-1.2785     </td><td>1.0285      </td><td> 0.05660    </td><td>-0.035263725</td><td>0.4854652   </td><td>-1.0143     </td><td>1.1332      </td><td>-0.03650    </td><td>...         </td><td>0.7048400   </td><td>-2.1237     </td><td>1.8689      </td><td> 0.11100    </td><td>0.8571800   </td><td>0.4493956   </td><td>0.164       </td><td>2.222       </td><td>0.8120      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>386</th><td> 0.017670707</td><td>0.6981887   </td><td>-1.5387     </td><td>2.1808      </td><td>-0.04500    </td><td> 0.043603191</td><td>1.2152972   </td><td>-2.6631     </td><td>3.1973      </td><td> 0.09380    </td><td>...         </td><td>0.8017314   </td><td>-1.6094     </td><td>1.2922      </td><td>-0.10680    </td><td>1.4910700   </td><td>0.5158915   </td><td>0.376       </td><td>2.428       </td><td>1.5820      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>387</th><td> 0.017401000</td><td>0.7680463   </td><td>-1.4528     </td><td>2.2822      </td><td>-0.00350    </td><td> 0.055612871</td><td>1.0989870   </td><td>-2.7737     </td><td>2.3134      </td><td> 0.16785    </td><td>...         </td><td>1.0468209   </td><td>-2.8051     </td><td>1.7055      </td><td>-0.01470    </td><td>1.5737525   </td><td>0.6825190   </td><td>0.428       </td><td>2.988       </td><td>1.5810      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>388</th><td> 0.001363636</td><td>0.4354711   </td><td>-1.0677     </td><td>0.9579      </td><td> 0.03655    </td><td>-0.017115842</td><td>0.5501718   </td><td>-1.1134     </td><td>1.0798      </td><td>-0.01640    </td><td>...         </td><td>0.7466890   </td><td>-2.1237     </td><td>2.0555      </td><td> 0.02230    </td><td>0.9342100   </td><td>0.4437911   </td><td>0.266       </td><td>2.222       </td><td>0.8410      </td><td>1           </td></tr>\n",
       "\t<tr><th scope=row>389</th><td> 0.036087000</td><td>0.8741671   </td><td>-2.2967     </td><td>3.3393      </td><td>-0.03330    </td><td>-0.019919792</td><td>1.4065464   </td><td>-2.9778     </td><td>3.0511      </td><td>-0.04680    </td><td>...         </td><td>1.2155255   </td><td>-3.8281     </td><td>1.9302      </td><td> 0.08820    </td><td>1.8953800   </td><td>0.7778120   </td><td>0.242       </td><td>4.098       </td><td>1.9170      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>390</th><td> 0.007588000</td><td>0.8409728   </td><td>-1.9602     </td><td>2.2383      </td><td>-0.07985    </td><td> 0.025797000</td><td>1.3525870   </td><td>-3.1511     </td><td>2.7414      </td><td>-0.02135    </td><td>...         </td><td>1.4189884   </td><td>-3.6947     </td><td>2.7486      </td><td>-0.14945    </td><td>1.9648889   </td><td>0.8489206   </td><td>0.397       </td><td>3.963       </td><td>1.8600      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>391</th><td> 0.065754545</td><td>0.4533416   </td><td>-0.7769     </td><td>1.1179      </td><td> 0.10470    </td><td> 0.047955446</td><td>0.5539467   </td><td>-0.9340     </td><td>1.0356      </td><td> 0.03360    </td><td>...         </td><td>0.7569361   </td><td>-2.1362     </td><td>2.3655      </td><td>-0.10495    </td><td>0.9663913   </td><td>0.4276036   </td><td>0.285       </td><td>2.353       </td><td>0.8930      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>392</th><td>-0.030526733</td><td>0.4442709   </td><td>-1.7119     </td><td>1.0302      </td><td> 0.03000    </td><td>-0.021866667</td><td>0.6103892   </td><td>-1.0198     </td><td>1.6418      </td><td>-0.01105    </td><td>...         </td><td>1.4149706   </td><td>-3.3599     </td><td>5.0202      </td><td>-0.11600    </td><td>1.3062900   </td><td>0.7562042   </td><td>0.131       </td><td>4.443       </td><td>1.1075      </td><td>1           </td></tr>\n",
       "\t<tr><th scope=row>393</th><td>-0.001643000</td><td>0.8086920   </td><td>-1.9033     </td><td>2.5242      </td><td>-0.03200    </td><td>-0.033747959</td><td>1.3111909   </td><td>-3.0231     </td><td>2.3208      </td><td> 0.01690    </td><td>...         </td><td>1.1671442   </td><td>-3.7451     </td><td>2.0425      </td><td>-0.19155    </td><td>1.7976224   </td><td>0.7133729   </td><td>0.326       </td><td>3.651       </td><td>1.7310      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>394</th><td>-0.023916346</td><td>0.4139117   </td><td>-0.6977     </td><td>1.1179      </td><td>-0.04360    </td><td> 0.011312000</td><td>0.4828770   </td><td>-1.2828     </td><td>1.1237      </td><td> 0.04940    </td><td>...         </td><td>0.7135787   </td><td>-1.9553     </td><td>1.8769      </td><td>-0.23950    </td><td>0.8609714   </td><td>0.4064190   </td><td>0.054       </td><td>2.031       </td><td>0.7900      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>395</th><td> 0.037914706</td><td>0.4369138   </td><td>-0.9701     </td><td>0.9937      </td><td> 0.07080    </td><td>-0.011703810</td><td>0.4883374   </td><td>-1.0822     </td><td>1.1166      </td><td>-0.08405    </td><td>...         </td><td>0.7141977   </td><td>-1.9285     </td><td>2.0766      </td><td> 0.08010    </td><td>0.8621584   </td><td>0.4222442   </td><td>0.193       </td><td>2.180       </td><td>0.7910      </td><td>2           </td></tr>\n",
       "\t<tr><th scope=row>396</th><td>-0.024820792</td><td>0.8127135   </td><td>-1.9299     </td><td>2.6378      </td><td> 0.01800    </td><td>-0.044580000</td><td>1.1363141   </td><td>-2.5429     </td><td>2.4081      </td><td>-0.12910    </td><td>...         </td><td>1.0066063   </td><td>-2.4043     </td><td>1.5056      </td><td>-0.12860    </td><td>1.6121359   </td><td>0.5853224   </td><td>0.052       </td><td>2.517       </td><td>1.6945      </td><td>4           </td></tr>\n",
       "\t<tr><th scope=row>397</th><td>-0.016237500</td><td>0.7620745   </td><td>-2.4099     </td><td>1.7855      </td><td>-0.05150    </td><td> 0.032355102</td><td>1.1534694   </td><td>-2.6734     </td><td>2.4506      </td><td> 0.07725    </td><td>...         </td><td>1.4259974   </td><td>-4.1238     </td><td>4.2297      </td><td>-0.24790    </td><td>1.7976224   </td><td>0.9082928   </td><td>0.212       </td><td>5.397       </td><td>1.6595      </td><td>3           </td></tr>\n",
       "\t<tr><th scope=row>398</th><td>-0.039379208</td><td>0.5614528   </td><td>-1.7119     </td><td>1.4600      </td><td>-0.11620    </td><td>-0.032463000</td><td>1.1096189   </td><td>-2.4111     </td><td>2.4533      </td><td>-0.09910    </td><td>...         </td><td>1.1076786   </td><td>-3.1215     </td><td>2.2947      </td><td>-0.14000    </td><td>1.5025833   </td><td>0.7521618   </td><td>0.168       </td><td>3.790       </td><td>1.4420      </td><td>3           </td></tr>\n",
       "\t<tr><th scope=row>399</th><td> 0.026206186</td><td>0.7980083   </td><td>-1.9033     </td><td>2.3863      </td><td> 0.00210    </td><td> 0.009870874</td><td>1.2557210   </td><td>-2.8507     </td><td>2.4343      </td><td> 0.13105    </td><td>...         </td><td>1.2135140   </td><td>-2.5112     </td><td>2.1638      </td><td>-0.22680    </td><td>1.7924158   </td><td>0.6828006   </td><td>0.397       </td><td>3.197       </td><td>1.7150      </td><td>3           </td></tr>\n",
       "\t<tr><th scope=row>400</th><td> 0.072777778</td><td>0.4051881   </td><td>-0.8386     </td><td>0.8847      </td><td> 0.15575    </td><td> 0.015370408</td><td>0.4759174   </td><td>-0.9340     </td><td>1.2039      </td><td> 0.01090    </td><td>...         </td><td>0.7135787   </td><td>-2.1186     </td><td>1.5632      </td><td>-0.13970    </td><td>0.9087400   </td><td>0.3767882   </td><td>0.170       </td><td>2.507       </td><td>0.8120      </td><td>1           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & ax\\_mean & ax\\_sd & ax\\_min & ax\\_max & ax\\_median & ay\\_mean & ay\\_sd & ay\\_min & ay\\_may & ay\\_median & ... & az\\_sd & az\\_min & az\\_maz & az\\_median & aT\\_mean & aT\\_sd & aT\\_min & aT\\_maT & aT\\_median & y\\\\\n",
       "\\hline\n",
       "\t351 & -0.016097030 & 0.8938523    & -2.3445      & 2.3006       & -0.07360     & -0.009759406 & 1.3118166    & -3.4215      & 2.5028       &  0.10890     & ...          & 1.2645719    & -2.8751      & 3.3718       & -0.07070     & 1.8660297    & 0.7808319    & 0.380        & 4.098        & 1.8200       & 4           \\\\\n",
       "\t352 & -0.015565347 & 0.8956615    & -2.2661      & 2.5089       &  0.08640     &  0.027313861 & 1.2940627    & -2.9421      & 2.3497       &  0.15260     & ...          & 1.3685757    & -3.3165      & 2.6989       & -0.01660     & 1.9304257    & 0.7749686    & 0.127        & 4.463        & 1.8350       & 4           \\\\\n",
       "\t353 &  0.024006250 & 0.8653758    & -2.4099      & 2.5328       & -0.03170     &  0.008440625 & 1.3763983    & -3.0422      & 2.3727       &  0.11390     & ...          & 1.4497833    & -4.2171      & 4.7703       &  0.00110     & 2.0035521    & 0.8300253    & 0.387        & 5.138        & 1.9920       & 4           \\\\\n",
       "\t354 & -0.015563000 & 0.8720967    & -2.3451      & 2.3269       & -0.05325     &  0.013962000 & 1.2400913    & -3.1360      & 2.8563       &  0.09145     & ...          & 1.4189884    & -3.3758      & 3.4279       & -0.10410     & 1.8953800    & 0.8351505    & 0.173        & 4.458        & 1.8735       & 4           \\\\\n",
       "\t355 &  0.003894898 & 0.8806773    & -2.3098      & 3.1902       & -0.09260     &  0.022575510 & 1.3019546    & -3.2561      & 2.7833       & -0.05380     & ...          & 1.2717989    & -3.8035      & 3.1323       & -0.26115     & 1.8522653    & 0.7909640    & 0.436        & 3.944        & 1.7570       & 4           \\\\\n",
       "\t356 & -0.039379208 & 0.8127135    & -2.1523      & 1.8828       & -0.11250     &  0.005454455 & 1.1895194    & -2.8057      & 2.4852       &  0.03040     & ...          & 1.3663678    & -3.3928      & 2.4507       &  0.05430     & 1.8280594    & 0.7562042    & 0.580        & 3.573        & 1.6960       & 4           \\\\\n",
       "\t357 &  0.021469000 & 0.8272527    & -1.5895      & 3.7505       & -0.08995     &  0.011312000 & 1.2852056    & -2.7423      & 2.6785       & -0.03640     & ...          & 1.1770121    & -2.6649      & 2.1685       &  0.02755     & 1.7859300    & 0.7120829    & 0.298        & 3.895        & 1.7575       & 4           \\\\\n",
       "\t358 &  0.005917000 & 0.9139808    & -2.3310      & 2.8131       & -0.07800     & -0.040868000 & 1.3208731    & -2.9778      & 2.2841       & -0.01435     & ...          & 1.4015674    & -3.3728      & 3.3165       &  0.19485     & 1.9475700    & 0.8513573    & 0.397        & 4.191        & 1.8180       & 4           \\\\\n",
       "\t359 & -0.034448571 & 0.8640626    & -2.4917      & 2.4113       & -0.01960     & -0.013410476 & 1.2351957    & -3.3305      & 2.4912       &  0.09420     & ...          & 1.3278861    & -2.9864      & 2.8430       & -0.05300     & 1.8825905    & 0.6971337    & 0.370        & 3.775        & 1.9030       & 4           \\\\\n",
       "\t360 &  0.046837374 & 0.9776022    & -1.8688      & 2.6644       & -0.03600     &  0.019817172 & 1.2936436    & -2.7836      & 2.6166       &  0.12540     & ...          & 1.2459059    & -2.4813      & 3.2677       & -0.11460     & 1.9016465    & 0.7296095    & 0.283        & 3.813        & 1.8440       & 4           \\\\\n",
       "\t361 & -0.014453061 & 0.9553743    & -2.7118      & 2.4640       & -0.01000     & -0.037717347 & 1.2853576    & -3.1225      & 2.4506       &  0.03085     & ...          & 1.4572321    & -4.2512      & 3.3754       &  0.09325     & 1.9844184    & 0.8511168    & 0.446        & 4.351        & 1.8600       & 4           \\\\\n",
       "\t362 &  0.046810870 & 0.9259427    & -1.5309      & 1.9420       & -0.11455     &  0.230676087 & 1.4919834    & -2.8435      & 2.8405       &  0.33060     & ...          & 1.1112049    & -2.1748      & 2.9009       & -0.03790     & 1.9271739    & 0.7622031    & 0.491        & 3.355        & 2.1620       & 4           \\\\\n",
       "\t363 &  0.011238614 & 0.8127502    & -1.9602      & 2.1430       &  0.00680     & -0.013367308 & 1.3019546    & -3.0628      & 2.7338       &  0.00070     & ...          & 1.4534581    & -4.4325      & 2.9648       & -0.03520     & 1.9383000    & 0.8526128    & 0.373        & 4.351        & 1.8705       & 4           \\\\\n",
       "\t364 & -0.009812264 & 0.7680463    & -2.3492      & 1.3919       &  0.03110     &  0.013984158 & 0.6084791    & -1.4155      & 0.9273       &  0.11860     & ...          & 0.9997898    & -3.0031      & 3.5781       & -0.25930     & 1.2219510    & 0.6450616    & 0.233        & 3.603        & 1.0730       & 1           \\\\\n",
       "\t365 & -0.026760000 & 0.4780558    & -1.1826      & 0.9934       &  0.05560     & -0.035218269 & 0.5632648    & -1.0761      & 1.2307       & -0.08165     & ...          & 0.7635922    & -2.3115      & 1.8934       &  0.03005     & 0.9714200    & 0.4214891    & 0.214        & 2.180        & 0.9265       & 1           \\\\\n",
       "\t366 &  0.029083000 & 0.7515921    & -2.2628      & 2.4640       & -0.00820     &  0.011159596 & 1.3073606    & -3.1360      & 2.8527       &  0.04010     & ...          & 1.4534581    & -3.6751      & 2.6187       & -0.22680     & 1.9367549    & 0.7439326    & 0.354        & 4.156        & 1.8450       & 4           \\\\\n",
       "\t367 &  0.002401000 & 0.5641062    & -1.1533      & 1.4479       & -0.04215     &  0.011159596 & 1.0358946    & -1.9856      & 2.9217       & -0.07040     & ...          & 0.7141977    & -1.7791      & 1.3013       & -0.20785     & 1.2607358    & 0.4523664    & 0.376        & 2.106        & 1.2830       & 4           \\\\\n",
       "\t368 &  0.017670707 & 0.4158231    & -0.9785      & 1.0647       &  0.07680     & -0.026719608 & 0.4759174    & -0.9340      & 0.9077       & -0.03650     & ...          & 0.6919936    & -1.6094      & 2.0555       & -0.19365     & 0.8742105    & 0.3962710    & 0.230        & 2.123        & 0.8120       & 1           \\\\\n",
       "\t369 & -0.078038776 & 0.4413032    & -1.1099      & 0.9826       & -0.03910     & -0.010626042 & 0.4768587    & -0.9392      & 0.8497       & -0.04655     & ...          & 0.8165436    & -2.2936      & 2.1036       & -0.29570     & 0.9319524    & 0.4517633    & 0.193        & 2.380        & 0.8865       & 2           \\\\\n",
       "\t370 &  0.004372632 & 0.8352791    & -1.6966      & 2.3897       &  0.00845     & -0.010064000 & 1.2746954    & -2.7832      & 2.2841       &  0.03085     & ...          & 1.2177225    & -3.1289      & 3.0919       &  0.01905     & 1.7844653    & 0.7343952    & 0.489        & 3.764        & 1.7520       & 3           \\\\\n",
       "\t371 &  0.016103000 & 0.3997476    & -0.9537      & 1.1546       &  0.03655     & -0.031622772 & 0.4828770    & -0.9772      & 1.1237       & -0.14540     & ...          & 0.7672163    & -1.9821      & 1.8173       & -0.09240     & 0.9053800    & 0.4160549    & 0.201        & 2.053        & 0.8520       & 2           \\\\\n",
       "\t372 & -0.020355446 & 0.4178729    & -1.0524      & 0.9076       & -0.09340     &  0.044400000 & 0.5439558    & -0.9843      & 1.0798       &  0.14000     & ...          & 0.7552593    & -2.0607      & 1.6134       & -0.17990     & 0.9498911    & 0.3846176    & 0.222        & 1.752        & 0.8950       & 1           \\\\\n",
       "\t373 &  0.001363636 & 0.4868077    & -0.9027      & 1.5155       &  0.04820     &  0.031339000 & 1.0619675    & -2.3261      & 2.4081       & -0.00210     & ...          & 0.7598489    & -1.7482      & 1.3013       & -0.20075     & 1.3272772    & 0.4315494    & 0.478        & 2.288        & 1.3220       & 4           \\\\\n",
       "\t374 & -0.008122222 & 0.8831968    & -1.9394      & 3.3244       & -0.09610     &  0.017400971 & 1.3778757    & -3.7580      & 2.4527       &  0.16935     & ...          & 1.4260617    & -3.1893      & 3.5781       &  0.09325     & 1.9576857    & 0.9167571    & 0.295        & 4.830        & 1.9430       & 4           \\\\\n",
       "\t375 & -0.065401010 & 0.8489219    & -2.4871      & 2.1672       & -0.11250     & -0.043491753 & 0.5648206    & -1.5188      & 0.8497       &  0.05440     & ...          & 1.4259974    & -3.1893      & 4.6557       &  0.08010     & 1.4950297    & 0.8012418    & 0.198        & 4.290        & 1.2550       & 1           \\\\\n",
       "\t376 &  0.039720000 & 0.5946125    & -1.5250      & 1.7390       &  0.05040     &  0.061424510 & 0.8133879    & -1.2303      & 1.6255       &  0.05660     & ...          & 0.9355264    & -2.2936      & 2.9202       &  0.02420     & 1.2507900    & 0.5391791    & 0.294        & 3.081        & 1.1770       & 3           \\\\\n",
       "\t377 &  0.022841000 & 0.8646867    & -2.1253      & 2.6378       &  0.05720     &  0.052515306 & 1.1332836    & -2.5429      & 2.3692       &  0.10620     & ...          & 1.0360114    & -3.0924      & 3.0590       &  0.00110     & 1.5811275    & 0.7053254    & 0.326        & 3.742        & 1.5815       & 3           \\\\\n",
       "\t378 & -0.001924510 & 0.5975310    & -1.4775      & 1.4089       & -0.11455     & -0.040868000 & 1.0363392    & -2.3289      & 2.2123       &  0.03025     & ...          & 0.7546022    & -1.6175      & 1.2922       & -0.18510     & 1.3324845    & 0.5131552    & 0.305        & 2.091        & 1.2830       & 4           \\\\\n",
       "\t379 &  0.017975000 & 0.4780750    & -1.2011      & 1.4923       & -0.07450     & -0.022319802 & 0.5072372    & -1.1404      & 1.0361       & -0.04135     & ...          & 0.7439169    & -2.0052      & 1.7066       & -0.09450     & 0.9151400    & 0.4541700    & 0.262        & 2.264        & 0.8270       & 2           \\\\\n",
       "\t380 & -0.070804000 & 0.4780558    & -1.9254      & 0.9244       & -0.05830     & -0.074927551 & 0.5037149    & -1.0485      & 1.0710       & -0.07750     & ...          & 0.7598489    & -2.1735      & 2.0385       & -0.24560     & 0.9281400    & 0.4813814    & 0.150        & 2.084        & 0.7900       & 2           \\\\\n",
       "\t381 & -0.002204762 & 0.9310547    & -2.7832      & 2.5242       & -0.07875     & -0.019305882 & 1.3019546    & -2.4215      & 2.8615       & -0.02880     & ...          & 1.1771775    & -3.0903      & 2.4800       & -0.19155     & 1.8377451    & 0.7254306    & 0.377        & 3.348        & 1.7770       & 4           \\\\\n",
       "\t382 &  0.021469000 & 0.8646867    & -2.0001      & 2.4477       & -0.03400     &  0.051977895 & 1.3628383    & -2.6574      & 2.7414       &  0.15305     & ...          & 1.1474602    & -2.9516      & 2.6371       &  0.08870     & 1.7884124    & 0.7520192    & 0.400        & 3.651        & 1.9180       & 4           \\\\\n",
       "\t383 & -0.015468354 & 0.8127502    & -2.2034      & 2.3405       & -0.02150     &  0.046179798 & 1.3628383    & -2.8594      & 2.7288       &  0.02130     & ...          & 1.1112049    & -4.2171      & 1.7215       &  0.09600     & 1.7592828    & 0.7680118    & 0.295        & 3.671        & 1.7780       & 4           \\\\\n",
       "\t384 & -0.002143000 & 0.4442709    & -0.9949      & 1.0734       & -0.04265     & -0.007904000 & 0.5386439    & -1.2828      & 1.2250       & -0.06765     & ...          & 0.7335329    & -2.2694      & 2.1640       & -0.30150     & 0.9293627    & 0.4517633    & 0.266        & 2.407        & 0.8000       & 2           \\\\\n",
       "\t385 &  0.027587129 & 0.4551125    & -1.2785      & 1.0285       &  0.05660     & -0.035263725 & 0.4854652    & -1.0143      & 1.1332       & -0.03650     & ...          & 0.7048400    & -2.1237      & 1.8689       &  0.11100     & 0.8571800    & 0.4493956    & 0.164        & 2.222        & 0.8120       & 2           \\\\\n",
       "\t386 &  0.017670707 & 0.6981887    & -1.5387      & 2.1808       & -0.04500     &  0.043603191 & 1.2152972    & -2.6631      & 3.1973       &  0.09380     & ...          & 0.8017314    & -1.6094      & 1.2922       & -0.10680     & 1.4910700    & 0.5158915    & 0.376        & 2.428        & 1.5820       & 4           \\\\\n",
       "\t387 &  0.017401000 & 0.7680463    & -1.4528      & 2.2822       & -0.00350     &  0.055612871 & 1.0989870    & -2.7737      & 2.3134       &  0.16785     & ...          & 1.0468209    & -2.8051      & 1.7055       & -0.01470     & 1.5737525    & 0.6825190    & 0.428        & 2.988        & 1.5810       & 4           \\\\\n",
       "\t388 &  0.001363636 & 0.4354711    & -1.0677      & 0.9579       &  0.03655     & -0.017115842 & 0.5501718    & -1.1134      & 1.0798       & -0.01640     & ...          & 0.7466890    & -2.1237      & 2.0555       &  0.02230     & 0.9342100    & 0.4437911    & 0.266        & 2.222        & 0.8410       & 1           \\\\\n",
       "\t389 &  0.036087000 & 0.8741671    & -2.2967      & 3.3393       & -0.03330     & -0.019919792 & 1.4065464    & -2.9778      & 3.0511       & -0.04680     & ...          & 1.2155255    & -3.8281      & 1.9302       &  0.08820     & 1.8953800    & 0.7778120    & 0.242        & 4.098        & 1.9170       & 4           \\\\\n",
       "\t390 &  0.007588000 & 0.8409728    & -1.9602      & 2.2383       & -0.07985     &  0.025797000 & 1.3525870    & -3.1511      & 2.7414       & -0.02135     & ...          & 1.4189884    & -3.6947      & 2.7486       & -0.14945     & 1.9648889    & 0.8489206    & 0.397        & 3.963        & 1.8600       & 4           \\\\\n",
       "\t391 &  0.065754545 & 0.4533416    & -0.7769      & 1.1179       &  0.10470     &  0.047955446 & 0.5539467    & -0.9340      & 1.0356       &  0.03360     & ...          & 0.7569361    & -2.1362      & 2.3655       & -0.10495     & 0.9663913    & 0.4276036    & 0.285        & 2.353        & 0.8930       & 2           \\\\\n",
       "\t392 & -0.030526733 & 0.4442709    & -1.7119      & 1.0302       &  0.03000     & -0.021866667 & 0.6103892    & -1.0198      & 1.6418       & -0.01105     & ...          & 1.4149706    & -3.3599      & 5.0202       & -0.11600     & 1.3062900    & 0.7562042    & 0.131        & 4.443        & 1.1075       & 1           \\\\\n",
       "\t393 & -0.001643000 & 0.8086920    & -1.9033      & 2.5242       & -0.03200     & -0.033747959 & 1.3111909    & -3.0231      & 2.3208       &  0.01690     & ...          & 1.1671442    & -3.7451      & 2.0425       & -0.19155     & 1.7976224    & 0.7133729    & 0.326        & 3.651        & 1.7310       & 4           \\\\\n",
       "\t394 & -0.023916346 & 0.4139117    & -0.6977      & 1.1179       & -0.04360     &  0.011312000 & 0.4828770    & -1.2828      & 1.1237       &  0.04940     & ...          & 0.7135787    & -1.9553      & 1.8769       & -0.23950     & 0.8609714    & 0.4064190    & 0.054        & 2.031        & 0.7900       & 2           \\\\\n",
       "\t395 &  0.037914706 & 0.4369138    & -0.9701      & 0.9937       &  0.07080     & -0.011703810 & 0.4883374    & -1.0822      & 1.1166       & -0.08405     & ...          & 0.7141977    & -1.9285      & 2.0766       &  0.08010     & 0.8621584    & 0.4222442    & 0.193        & 2.180        & 0.7910       & 2           \\\\\n",
       "\t396 & -0.024820792 & 0.8127135    & -1.9299      & 2.6378       &  0.01800     & -0.044580000 & 1.1363141    & -2.5429      & 2.4081       & -0.12910     & ...          & 1.0066063    & -2.4043      & 1.5056       & -0.12860     & 1.6121359    & 0.5853224    & 0.052        & 2.517        & 1.6945       & 4           \\\\\n",
       "\t397 & -0.016237500 & 0.7620745    & -2.4099      & 1.7855       & -0.05150     &  0.032355102 & 1.1534694    & -2.6734      & 2.4506       &  0.07725     & ...          & 1.4259974    & -4.1238      & 4.2297       & -0.24790     & 1.7976224    & 0.9082928    & 0.212        & 5.397        & 1.6595       & 3           \\\\\n",
       "\t398 & -0.039379208 & 0.5614528    & -1.7119      & 1.4600       & -0.11620     & -0.032463000 & 1.1096189    & -2.4111      & 2.4533       & -0.09910     & ...          & 1.1076786    & -3.1215      & 2.2947       & -0.14000     & 1.5025833    & 0.7521618    & 0.168        & 3.790        & 1.4420       & 3           \\\\\n",
       "\t399 &  0.026206186 & 0.7980083    & -1.9033      & 2.3863       &  0.00210     &  0.009870874 & 1.2557210    & -2.8507      & 2.4343       &  0.13105     & ...          & 1.2135140    & -2.5112      & 2.1638       & -0.22680     & 1.7924158    & 0.6828006    & 0.397        & 3.197        & 1.7150       & 3           \\\\\n",
       "\t400 &  0.072777778 & 0.4051881    & -0.8386      & 0.8847       &  0.15575     &  0.015370408 & 0.4759174    & -0.9340      & 1.2039       &  0.01090     & ...          & 0.7135787    & -2.1186      & 1.5632       & -0.13970     & 0.9087400    & 0.3767882    & 0.170        & 2.507        & 0.8120       & 1           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | ax_mean | ax_sd | ax_min | ax_max | ax_median | ay_mean | ay_sd | ay_min | ay_may | ay_median | ... | az_sd | az_min | az_maz | az_median | aT_mean | aT_sd | aT_min | aT_maT | aT_median | y |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 351 | -0.016097030 | 0.8938523    | -2.3445      | 2.3006       | -0.07360     | -0.009759406 | 1.3118166    | -3.4215      | 2.5028       |  0.10890     | ...          | 1.2645719    | -2.8751      | 3.3718       | -0.07070     | 1.8660297    | 0.7808319    | 0.380        | 4.098        | 1.8200       | 4            |\n",
       "| 352 | -0.015565347 | 0.8956615    | -2.2661      | 2.5089       |  0.08640     |  0.027313861 | 1.2940627    | -2.9421      | 2.3497       |  0.15260     | ...          | 1.3685757    | -3.3165      | 2.6989       | -0.01660     | 1.9304257    | 0.7749686    | 0.127        | 4.463        | 1.8350       | 4            |\n",
       "| 353 |  0.024006250 | 0.8653758    | -2.4099      | 2.5328       | -0.03170     |  0.008440625 | 1.3763983    | -3.0422      | 2.3727       |  0.11390     | ...          | 1.4497833    | -4.2171      | 4.7703       |  0.00110     | 2.0035521    | 0.8300253    | 0.387        | 5.138        | 1.9920       | 4            |\n",
       "| 354 | -0.015563000 | 0.8720967    | -2.3451      | 2.3269       | -0.05325     |  0.013962000 | 1.2400913    | -3.1360      | 2.8563       |  0.09145     | ...          | 1.4189884    | -3.3758      | 3.4279       | -0.10410     | 1.8953800    | 0.8351505    | 0.173        | 4.458        | 1.8735       | 4            |\n",
       "| 355 |  0.003894898 | 0.8806773    | -2.3098      | 3.1902       | -0.09260     |  0.022575510 | 1.3019546    | -3.2561      | 2.7833       | -0.05380     | ...          | 1.2717989    | -3.8035      | 3.1323       | -0.26115     | 1.8522653    | 0.7909640    | 0.436        | 3.944        | 1.7570       | 4            |\n",
       "| 356 | -0.039379208 | 0.8127135    | -2.1523      | 1.8828       | -0.11250     |  0.005454455 | 1.1895194    | -2.8057      | 2.4852       |  0.03040     | ...          | 1.3663678    | -3.3928      | 2.4507       |  0.05430     | 1.8280594    | 0.7562042    | 0.580        | 3.573        | 1.6960       | 4            |\n",
       "| 357 |  0.021469000 | 0.8272527    | -1.5895      | 3.7505       | -0.08995     |  0.011312000 | 1.2852056    | -2.7423      | 2.6785       | -0.03640     | ...          | 1.1770121    | -2.6649      | 2.1685       |  0.02755     | 1.7859300    | 0.7120829    | 0.298        | 3.895        | 1.7575       | 4            |\n",
       "| 358 |  0.005917000 | 0.9139808    | -2.3310      | 2.8131       | -0.07800     | -0.040868000 | 1.3208731    | -2.9778      | 2.2841       | -0.01435     | ...          | 1.4015674    | -3.3728      | 3.3165       |  0.19485     | 1.9475700    | 0.8513573    | 0.397        | 4.191        | 1.8180       | 4            |\n",
       "| 359 | -0.034448571 | 0.8640626    | -2.4917      | 2.4113       | -0.01960     | -0.013410476 | 1.2351957    | -3.3305      | 2.4912       |  0.09420     | ...          | 1.3278861    | -2.9864      | 2.8430       | -0.05300     | 1.8825905    | 0.6971337    | 0.370        | 3.775        | 1.9030       | 4            |\n",
       "| 360 |  0.046837374 | 0.9776022    | -1.8688      | 2.6644       | -0.03600     |  0.019817172 | 1.2936436    | -2.7836      | 2.6166       |  0.12540     | ...          | 1.2459059    | -2.4813      | 3.2677       | -0.11460     | 1.9016465    | 0.7296095    | 0.283        | 3.813        | 1.8440       | 4            |\n",
       "| 361 | -0.014453061 | 0.9553743    | -2.7118      | 2.4640       | -0.01000     | -0.037717347 | 1.2853576    | -3.1225      | 2.4506       |  0.03085     | ...          | 1.4572321    | -4.2512      | 3.3754       |  0.09325     | 1.9844184    | 0.8511168    | 0.446        | 4.351        | 1.8600       | 4            |\n",
       "| 362 |  0.046810870 | 0.9259427    | -1.5309      | 1.9420       | -0.11455     |  0.230676087 | 1.4919834    | -2.8435      | 2.8405       |  0.33060     | ...          | 1.1112049    | -2.1748      | 2.9009       | -0.03790     | 1.9271739    | 0.7622031    | 0.491        | 3.355        | 2.1620       | 4            |\n",
       "| 363 |  0.011238614 | 0.8127502    | -1.9602      | 2.1430       |  0.00680     | -0.013367308 | 1.3019546    | -3.0628      | 2.7338       |  0.00070     | ...          | 1.4534581    | -4.4325      | 2.9648       | -0.03520     | 1.9383000    | 0.8526128    | 0.373        | 4.351        | 1.8705       | 4            |\n",
       "| 364 | -0.009812264 | 0.7680463    | -2.3492      | 1.3919       |  0.03110     |  0.013984158 | 0.6084791    | -1.4155      | 0.9273       |  0.11860     | ...          | 0.9997898    | -3.0031      | 3.5781       | -0.25930     | 1.2219510    | 0.6450616    | 0.233        | 3.603        | 1.0730       | 1            |\n",
       "| 365 | -0.026760000 | 0.4780558    | -1.1826      | 0.9934       |  0.05560     | -0.035218269 | 0.5632648    | -1.0761      | 1.2307       | -0.08165     | ...          | 0.7635922    | -2.3115      | 1.8934       |  0.03005     | 0.9714200    | 0.4214891    | 0.214        | 2.180        | 0.9265       | 1            |\n",
       "| 366 |  0.029083000 | 0.7515921    | -2.2628      | 2.4640       | -0.00820     |  0.011159596 | 1.3073606    | -3.1360      | 2.8527       |  0.04010     | ...          | 1.4534581    | -3.6751      | 2.6187       | -0.22680     | 1.9367549    | 0.7439326    | 0.354        | 4.156        | 1.8450       | 4            |\n",
       "| 367 |  0.002401000 | 0.5641062    | -1.1533      | 1.4479       | -0.04215     |  0.011159596 | 1.0358946    | -1.9856      | 2.9217       | -0.07040     | ...          | 0.7141977    | -1.7791      | 1.3013       | -0.20785     | 1.2607358    | 0.4523664    | 0.376        | 2.106        | 1.2830       | 4            |\n",
       "| 368 |  0.017670707 | 0.4158231    | -0.9785      | 1.0647       |  0.07680     | -0.026719608 | 0.4759174    | -0.9340      | 0.9077       | -0.03650     | ...          | 0.6919936    | -1.6094      | 2.0555       | -0.19365     | 0.8742105    | 0.3962710    | 0.230        | 2.123        | 0.8120       | 1            |\n",
       "| 369 | -0.078038776 | 0.4413032    | -1.1099      | 0.9826       | -0.03910     | -0.010626042 | 0.4768587    | -0.9392      | 0.8497       | -0.04655     | ...          | 0.8165436    | -2.2936      | 2.1036       | -0.29570     | 0.9319524    | 0.4517633    | 0.193        | 2.380        | 0.8865       | 2            |\n",
       "| 370 |  0.004372632 | 0.8352791    | -1.6966      | 2.3897       |  0.00845     | -0.010064000 | 1.2746954    | -2.7832      | 2.2841       |  0.03085     | ...          | 1.2177225    | -3.1289      | 3.0919       |  0.01905     | 1.7844653    | 0.7343952    | 0.489        | 3.764        | 1.7520       | 3            |\n",
       "| 371 |  0.016103000 | 0.3997476    | -0.9537      | 1.1546       |  0.03655     | -0.031622772 | 0.4828770    | -0.9772      | 1.1237       | -0.14540     | ...          | 0.7672163    | -1.9821      | 1.8173       | -0.09240     | 0.9053800    | 0.4160549    | 0.201        | 2.053        | 0.8520       | 2            |\n",
       "| 372 | -0.020355446 | 0.4178729    | -1.0524      | 0.9076       | -0.09340     |  0.044400000 | 0.5439558    | -0.9843      | 1.0798       |  0.14000     | ...          | 0.7552593    | -2.0607      | 1.6134       | -0.17990     | 0.9498911    | 0.3846176    | 0.222        | 1.752        | 0.8950       | 1            |\n",
       "| 373 |  0.001363636 | 0.4868077    | -0.9027      | 1.5155       |  0.04820     |  0.031339000 | 1.0619675    | -2.3261      | 2.4081       | -0.00210     | ...          | 0.7598489    | -1.7482      | 1.3013       | -0.20075     | 1.3272772    | 0.4315494    | 0.478        | 2.288        | 1.3220       | 4            |\n",
       "| 374 | -0.008122222 | 0.8831968    | -1.9394      | 3.3244       | -0.09610     |  0.017400971 | 1.3778757    | -3.7580      | 2.4527       |  0.16935     | ...          | 1.4260617    | -3.1893      | 3.5781       |  0.09325     | 1.9576857    | 0.9167571    | 0.295        | 4.830        | 1.9430       | 4            |\n",
       "| 375 | -0.065401010 | 0.8489219    | -2.4871      | 2.1672       | -0.11250     | -0.043491753 | 0.5648206    | -1.5188      | 0.8497       |  0.05440     | ...          | 1.4259974    | -3.1893      | 4.6557       |  0.08010     | 1.4950297    | 0.8012418    | 0.198        | 4.290        | 1.2550       | 1            |\n",
       "| 376 |  0.039720000 | 0.5946125    | -1.5250      | 1.7390       |  0.05040     |  0.061424510 | 0.8133879    | -1.2303      | 1.6255       |  0.05660     | ...          | 0.9355264    | -2.2936      | 2.9202       |  0.02420     | 1.2507900    | 0.5391791    | 0.294        | 3.081        | 1.1770       | 3            |\n",
       "| 377 |  0.022841000 | 0.8646867    | -2.1253      | 2.6378       |  0.05720     |  0.052515306 | 1.1332836    | -2.5429      | 2.3692       |  0.10620     | ...          | 1.0360114    | -3.0924      | 3.0590       |  0.00110     | 1.5811275    | 0.7053254    | 0.326        | 3.742        | 1.5815       | 3            |\n",
       "| 378 | -0.001924510 | 0.5975310    | -1.4775      | 1.4089       | -0.11455     | -0.040868000 | 1.0363392    | -2.3289      | 2.2123       |  0.03025     | ...          | 0.7546022    | -1.6175      | 1.2922       | -0.18510     | 1.3324845    | 0.5131552    | 0.305        | 2.091        | 1.2830       | 4            |\n",
       "| 379 |  0.017975000 | 0.4780750    | -1.2011      | 1.4923       | -0.07450     | -0.022319802 | 0.5072372    | -1.1404      | 1.0361       | -0.04135     | ...          | 0.7439169    | -2.0052      | 1.7066       | -0.09450     | 0.9151400    | 0.4541700    | 0.262        | 2.264        | 0.8270       | 2            |\n",
       "| 380 | -0.070804000 | 0.4780558    | -1.9254      | 0.9244       | -0.05830     | -0.074927551 | 0.5037149    | -1.0485      | 1.0710       | -0.07750     | ...          | 0.7598489    | -2.1735      | 2.0385       | -0.24560     | 0.9281400    | 0.4813814    | 0.150        | 2.084        | 0.7900       | 2            |\n",
       "| 381 | -0.002204762 | 0.9310547    | -2.7832      | 2.5242       | -0.07875     | -0.019305882 | 1.3019546    | -2.4215      | 2.8615       | -0.02880     | ...          | 1.1771775    | -3.0903      | 2.4800       | -0.19155     | 1.8377451    | 0.7254306    | 0.377        | 3.348        | 1.7770       | 4            |\n",
       "| 382 |  0.021469000 | 0.8646867    | -2.0001      | 2.4477       | -0.03400     |  0.051977895 | 1.3628383    | -2.6574      | 2.7414       |  0.15305     | ...          | 1.1474602    | -2.9516      | 2.6371       |  0.08870     | 1.7884124    | 0.7520192    | 0.400        | 3.651        | 1.9180       | 4            |\n",
       "| 383 | -0.015468354 | 0.8127502    | -2.2034      | 2.3405       | -0.02150     |  0.046179798 | 1.3628383    | -2.8594      | 2.7288       |  0.02130     | ...          | 1.1112049    | -4.2171      | 1.7215       |  0.09600     | 1.7592828    | 0.7680118    | 0.295        | 3.671        | 1.7780       | 4            |\n",
       "| 384 | -0.002143000 | 0.4442709    | -0.9949      | 1.0734       | -0.04265     | -0.007904000 | 0.5386439    | -1.2828      | 1.2250       | -0.06765     | ...          | 0.7335329    | -2.2694      | 2.1640       | -0.30150     | 0.9293627    | 0.4517633    | 0.266        | 2.407        | 0.8000       | 2            |\n",
       "| 385 |  0.027587129 | 0.4551125    | -1.2785      | 1.0285       |  0.05660     | -0.035263725 | 0.4854652    | -1.0143      | 1.1332       | -0.03650     | ...          | 0.7048400    | -2.1237      | 1.8689       |  0.11100     | 0.8571800    | 0.4493956    | 0.164        | 2.222        | 0.8120       | 2            |\n",
       "| 386 |  0.017670707 | 0.6981887    | -1.5387      | 2.1808       | -0.04500     |  0.043603191 | 1.2152972    | -2.6631      | 3.1973       |  0.09380     | ...          | 0.8017314    | -1.6094      | 1.2922       | -0.10680     | 1.4910700    | 0.5158915    | 0.376        | 2.428        | 1.5820       | 4            |\n",
       "| 387 |  0.017401000 | 0.7680463    | -1.4528      | 2.2822       | -0.00350     |  0.055612871 | 1.0989870    | -2.7737      | 2.3134       |  0.16785     | ...          | 1.0468209    | -2.8051      | 1.7055       | -0.01470     | 1.5737525    | 0.6825190    | 0.428        | 2.988        | 1.5810       | 4            |\n",
       "| 388 |  0.001363636 | 0.4354711    | -1.0677      | 0.9579       |  0.03655     | -0.017115842 | 0.5501718    | -1.1134      | 1.0798       | -0.01640     | ...          | 0.7466890    | -2.1237      | 2.0555       |  0.02230     | 0.9342100    | 0.4437911    | 0.266        | 2.222        | 0.8410       | 1            |\n",
       "| 389 |  0.036087000 | 0.8741671    | -2.2967      | 3.3393       | -0.03330     | -0.019919792 | 1.4065464    | -2.9778      | 3.0511       | -0.04680     | ...          | 1.2155255    | -3.8281      | 1.9302       |  0.08820     | 1.8953800    | 0.7778120    | 0.242        | 4.098        | 1.9170       | 4            |\n",
       "| 390 |  0.007588000 | 0.8409728    | -1.9602      | 2.2383       | -0.07985     |  0.025797000 | 1.3525870    | -3.1511      | 2.7414       | -0.02135     | ...          | 1.4189884    | -3.6947      | 2.7486       | -0.14945     | 1.9648889    | 0.8489206    | 0.397        | 3.963        | 1.8600       | 4            |\n",
       "| 391 |  0.065754545 | 0.4533416    | -0.7769      | 1.1179       |  0.10470     |  0.047955446 | 0.5539467    | -0.9340      | 1.0356       |  0.03360     | ...          | 0.7569361    | -2.1362      | 2.3655       | -0.10495     | 0.9663913    | 0.4276036    | 0.285        | 2.353        | 0.8930       | 2            |\n",
       "| 392 | -0.030526733 | 0.4442709    | -1.7119      | 1.0302       |  0.03000     | -0.021866667 | 0.6103892    | -1.0198      | 1.6418       | -0.01105     | ...          | 1.4149706    | -3.3599      | 5.0202       | -0.11600     | 1.3062900    | 0.7562042    | 0.131        | 4.443        | 1.1075       | 1            |\n",
       "| 393 | -0.001643000 | 0.8086920    | -1.9033      | 2.5242       | -0.03200     | -0.033747959 | 1.3111909    | -3.0231      | 2.3208       |  0.01690     | ...          | 1.1671442    | -3.7451      | 2.0425       | -0.19155     | 1.7976224    | 0.7133729    | 0.326        | 3.651        | 1.7310       | 4            |\n",
       "| 394 | -0.023916346 | 0.4139117    | -0.6977      | 1.1179       | -0.04360     |  0.011312000 | 0.4828770    | -1.2828      | 1.1237       |  0.04940     | ...          | 0.7135787    | -1.9553      | 1.8769       | -0.23950     | 0.8609714    | 0.4064190    | 0.054        | 2.031        | 0.7900       | 2            |\n",
       "| 395 |  0.037914706 | 0.4369138    | -0.9701      | 0.9937       |  0.07080     | -0.011703810 | 0.4883374    | -1.0822      | 1.1166       | -0.08405     | ...          | 0.7141977    | -1.9285      | 2.0766       |  0.08010     | 0.8621584    | 0.4222442    | 0.193        | 2.180        | 0.7910       | 2            |\n",
       "| 396 | -0.024820792 | 0.8127135    | -1.9299      | 2.6378       |  0.01800     | -0.044580000 | 1.1363141    | -2.5429      | 2.4081       | -0.12910     | ...          | 1.0066063    | -2.4043      | 1.5056       | -0.12860     | 1.6121359    | 0.5853224    | 0.052        | 2.517        | 1.6945       | 4            |\n",
       "| 397 | -0.016237500 | 0.7620745    | -2.4099      | 1.7855       | -0.05150     |  0.032355102 | 1.1534694    | -2.6734      | 2.4506       |  0.07725     | ...          | 1.4259974    | -4.1238      | 4.2297       | -0.24790     | 1.7976224    | 0.9082928    | 0.212        | 5.397        | 1.6595       | 3            |\n",
       "| 398 | -0.039379208 | 0.5614528    | -1.7119      | 1.4600       | -0.11620     | -0.032463000 | 1.1096189    | -2.4111      | 2.4533       | -0.09910     | ...          | 1.1076786    | -3.1215      | 2.2947       | -0.14000     | 1.5025833    | 0.7521618    | 0.168        | 3.790        | 1.4420       | 3            |\n",
       "| 399 |  0.026206186 | 0.7980083    | -1.9033      | 2.3863       |  0.00210     |  0.009870874 | 1.2557210    | -2.8507      | 2.4343       |  0.13105     | ...          | 1.2135140    | -2.5112      | 2.1638       | -0.22680     | 1.7924158    | 0.6828006    | 0.397        | 3.197        | 1.7150       | 3            |\n",
       "| 400 |  0.072777778 | 0.4051881    | -0.8386      | 0.8847       |  0.15575     |  0.015370408 | 0.4759174    | -0.9340      | 1.2039       |  0.01090     | ...          | 0.7135787    | -2.1186      | 1.5632       | -0.13970     | 0.9087400    | 0.3767882    | 0.170        | 2.507        | 0.8120       | 1            |\n",
       "\n"
      ],
      "text/plain": [
       "    ax_mean      ax_sd     ax_min  ax_max ax_median ay_mean      ay_sd    \n",
       "351 -0.016097030 0.8938523 -2.3445 2.3006 -0.07360  -0.009759406 1.3118166\n",
       "352 -0.015565347 0.8956615 -2.2661 2.5089  0.08640   0.027313861 1.2940627\n",
       "353  0.024006250 0.8653758 -2.4099 2.5328 -0.03170   0.008440625 1.3763983\n",
       "354 -0.015563000 0.8720967 -2.3451 2.3269 -0.05325   0.013962000 1.2400913\n",
       "355  0.003894898 0.8806773 -2.3098 3.1902 -0.09260   0.022575510 1.3019546\n",
       "356 -0.039379208 0.8127135 -2.1523 1.8828 -0.11250   0.005454455 1.1895194\n",
       "357  0.021469000 0.8272527 -1.5895 3.7505 -0.08995   0.011312000 1.2852056\n",
       "358  0.005917000 0.9139808 -2.3310 2.8131 -0.07800  -0.040868000 1.3208731\n",
       "359 -0.034448571 0.8640626 -2.4917 2.4113 -0.01960  -0.013410476 1.2351957\n",
       "360  0.046837374 0.9776022 -1.8688 2.6644 -0.03600   0.019817172 1.2936436\n",
       "361 -0.014453061 0.9553743 -2.7118 2.4640 -0.01000  -0.037717347 1.2853576\n",
       "362  0.046810870 0.9259427 -1.5309 1.9420 -0.11455   0.230676087 1.4919834\n",
       "363  0.011238614 0.8127502 -1.9602 2.1430  0.00680  -0.013367308 1.3019546\n",
       "364 -0.009812264 0.7680463 -2.3492 1.3919  0.03110   0.013984158 0.6084791\n",
       "365 -0.026760000 0.4780558 -1.1826 0.9934  0.05560  -0.035218269 0.5632648\n",
       "366  0.029083000 0.7515921 -2.2628 2.4640 -0.00820   0.011159596 1.3073606\n",
       "367  0.002401000 0.5641062 -1.1533 1.4479 -0.04215   0.011159596 1.0358946\n",
       "368  0.017670707 0.4158231 -0.9785 1.0647  0.07680  -0.026719608 0.4759174\n",
       "369 -0.078038776 0.4413032 -1.1099 0.9826 -0.03910  -0.010626042 0.4768587\n",
       "370  0.004372632 0.8352791 -1.6966 2.3897  0.00845  -0.010064000 1.2746954\n",
       "371  0.016103000 0.3997476 -0.9537 1.1546  0.03655  -0.031622772 0.4828770\n",
       "372 -0.020355446 0.4178729 -1.0524 0.9076 -0.09340   0.044400000 0.5439558\n",
       "373  0.001363636 0.4868077 -0.9027 1.5155  0.04820   0.031339000 1.0619675\n",
       "374 -0.008122222 0.8831968 -1.9394 3.3244 -0.09610   0.017400971 1.3778757\n",
       "375 -0.065401010 0.8489219 -2.4871 2.1672 -0.11250  -0.043491753 0.5648206\n",
       "376  0.039720000 0.5946125 -1.5250 1.7390  0.05040   0.061424510 0.8133879\n",
       "377  0.022841000 0.8646867 -2.1253 2.6378  0.05720   0.052515306 1.1332836\n",
       "378 -0.001924510 0.5975310 -1.4775 1.4089 -0.11455  -0.040868000 1.0363392\n",
       "379  0.017975000 0.4780750 -1.2011 1.4923 -0.07450  -0.022319802 0.5072372\n",
       "380 -0.070804000 0.4780558 -1.9254 0.9244 -0.05830  -0.074927551 0.5037149\n",
       "381 -0.002204762 0.9310547 -2.7832 2.5242 -0.07875  -0.019305882 1.3019546\n",
       "382  0.021469000 0.8646867 -2.0001 2.4477 -0.03400   0.051977895 1.3628383\n",
       "383 -0.015468354 0.8127502 -2.2034 2.3405 -0.02150   0.046179798 1.3628383\n",
       "384 -0.002143000 0.4442709 -0.9949 1.0734 -0.04265  -0.007904000 0.5386439\n",
       "385  0.027587129 0.4551125 -1.2785 1.0285  0.05660  -0.035263725 0.4854652\n",
       "386  0.017670707 0.6981887 -1.5387 2.1808 -0.04500   0.043603191 1.2152972\n",
       "387  0.017401000 0.7680463 -1.4528 2.2822 -0.00350   0.055612871 1.0989870\n",
       "388  0.001363636 0.4354711 -1.0677 0.9579  0.03655  -0.017115842 0.5501718\n",
       "389  0.036087000 0.8741671 -2.2967 3.3393 -0.03330  -0.019919792 1.4065464\n",
       "390  0.007588000 0.8409728 -1.9602 2.2383 -0.07985   0.025797000 1.3525870\n",
       "391  0.065754545 0.4533416 -0.7769 1.1179  0.10470   0.047955446 0.5539467\n",
       "392 -0.030526733 0.4442709 -1.7119 1.0302  0.03000  -0.021866667 0.6103892\n",
       "393 -0.001643000 0.8086920 -1.9033 2.5242 -0.03200  -0.033747959 1.3111909\n",
       "394 -0.023916346 0.4139117 -0.6977 1.1179 -0.04360   0.011312000 0.4828770\n",
       "395  0.037914706 0.4369138 -0.9701 0.9937  0.07080  -0.011703810 0.4883374\n",
       "396 -0.024820792 0.8127135 -1.9299 2.6378  0.01800  -0.044580000 1.1363141\n",
       "397 -0.016237500 0.7620745 -2.4099 1.7855 -0.05150   0.032355102 1.1534694\n",
       "398 -0.039379208 0.5614528 -1.7119 1.4600 -0.11620  -0.032463000 1.1096189\n",
       "399  0.026206186 0.7980083 -1.9033 2.3863  0.00210   0.009870874 1.2557210\n",
       "400  0.072777778 0.4051881 -0.8386 0.8847  0.15575   0.015370408 0.4759174\n",
       "    ay_min  ay_may ay_median ... az_sd     az_min  az_maz az_median aT_mean  \n",
       "351 -3.4215 2.5028  0.10890  ... 1.2645719 -2.8751 3.3718 -0.07070  1.8660297\n",
       "352 -2.9421 2.3497  0.15260  ... 1.3685757 -3.3165 2.6989 -0.01660  1.9304257\n",
       "353 -3.0422 2.3727  0.11390  ... 1.4497833 -4.2171 4.7703  0.00110  2.0035521\n",
       "354 -3.1360 2.8563  0.09145  ... 1.4189884 -3.3758 3.4279 -0.10410  1.8953800\n",
       "355 -3.2561 2.7833 -0.05380  ... 1.2717989 -3.8035 3.1323 -0.26115  1.8522653\n",
       "356 -2.8057 2.4852  0.03040  ... 1.3663678 -3.3928 2.4507  0.05430  1.8280594\n",
       "357 -2.7423 2.6785 -0.03640  ... 1.1770121 -2.6649 2.1685  0.02755  1.7859300\n",
       "358 -2.9778 2.2841 -0.01435  ... 1.4015674 -3.3728 3.3165  0.19485  1.9475700\n",
       "359 -3.3305 2.4912  0.09420  ... 1.3278861 -2.9864 2.8430 -0.05300  1.8825905\n",
       "360 -2.7836 2.6166  0.12540  ... 1.2459059 -2.4813 3.2677 -0.11460  1.9016465\n",
       "361 -3.1225 2.4506  0.03085  ... 1.4572321 -4.2512 3.3754  0.09325  1.9844184\n",
       "362 -2.8435 2.8405  0.33060  ... 1.1112049 -2.1748 2.9009 -0.03790  1.9271739\n",
       "363 -3.0628 2.7338  0.00070  ... 1.4534581 -4.4325 2.9648 -0.03520  1.9383000\n",
       "364 -1.4155 0.9273  0.11860  ... 0.9997898 -3.0031 3.5781 -0.25930  1.2219510\n",
       "365 -1.0761 1.2307 -0.08165  ... 0.7635922 -2.3115 1.8934  0.03005  0.9714200\n",
       "366 -3.1360 2.8527  0.04010  ... 1.4534581 -3.6751 2.6187 -0.22680  1.9367549\n",
       "367 -1.9856 2.9217 -0.07040  ... 0.7141977 -1.7791 1.3013 -0.20785  1.2607358\n",
       "368 -0.9340 0.9077 -0.03650  ... 0.6919936 -1.6094 2.0555 -0.19365  0.8742105\n",
       "369 -0.9392 0.8497 -0.04655  ... 0.8165436 -2.2936 2.1036 -0.29570  0.9319524\n",
       "370 -2.7832 2.2841  0.03085  ... 1.2177225 -3.1289 3.0919  0.01905  1.7844653\n",
       "371 -0.9772 1.1237 -0.14540  ... 0.7672163 -1.9821 1.8173 -0.09240  0.9053800\n",
       "372 -0.9843 1.0798  0.14000  ... 0.7552593 -2.0607 1.6134 -0.17990  0.9498911\n",
       "373 -2.3261 2.4081 -0.00210  ... 0.7598489 -1.7482 1.3013 -0.20075  1.3272772\n",
       "374 -3.7580 2.4527  0.16935  ... 1.4260617 -3.1893 3.5781  0.09325  1.9576857\n",
       "375 -1.5188 0.8497  0.05440  ... 1.4259974 -3.1893 4.6557  0.08010  1.4950297\n",
       "376 -1.2303 1.6255  0.05660  ... 0.9355264 -2.2936 2.9202  0.02420  1.2507900\n",
       "377 -2.5429 2.3692  0.10620  ... 1.0360114 -3.0924 3.0590  0.00110  1.5811275\n",
       "378 -2.3289 2.2123  0.03025  ... 0.7546022 -1.6175 1.2922 -0.18510  1.3324845\n",
       "379 -1.1404 1.0361 -0.04135  ... 0.7439169 -2.0052 1.7066 -0.09450  0.9151400\n",
       "380 -1.0485 1.0710 -0.07750  ... 0.7598489 -2.1735 2.0385 -0.24560  0.9281400\n",
       "381 -2.4215 2.8615 -0.02880  ... 1.1771775 -3.0903 2.4800 -0.19155  1.8377451\n",
       "382 -2.6574 2.7414  0.15305  ... 1.1474602 -2.9516 2.6371  0.08870  1.7884124\n",
       "383 -2.8594 2.7288  0.02130  ... 1.1112049 -4.2171 1.7215  0.09600  1.7592828\n",
       "384 -1.2828 1.2250 -0.06765  ... 0.7335329 -2.2694 2.1640 -0.30150  0.9293627\n",
       "385 -1.0143 1.1332 -0.03650  ... 0.7048400 -2.1237 1.8689  0.11100  0.8571800\n",
       "386 -2.6631 3.1973  0.09380  ... 0.8017314 -1.6094 1.2922 -0.10680  1.4910700\n",
       "387 -2.7737 2.3134  0.16785  ... 1.0468209 -2.8051 1.7055 -0.01470  1.5737525\n",
       "388 -1.1134 1.0798 -0.01640  ... 0.7466890 -2.1237 2.0555  0.02230  0.9342100\n",
       "389 -2.9778 3.0511 -0.04680  ... 1.2155255 -3.8281 1.9302  0.08820  1.8953800\n",
       "390 -3.1511 2.7414 -0.02135  ... 1.4189884 -3.6947 2.7486 -0.14945  1.9648889\n",
       "391 -0.9340 1.0356  0.03360  ... 0.7569361 -2.1362 2.3655 -0.10495  0.9663913\n",
       "392 -1.0198 1.6418 -0.01105  ... 1.4149706 -3.3599 5.0202 -0.11600  1.3062900\n",
       "393 -3.0231 2.3208  0.01690  ... 1.1671442 -3.7451 2.0425 -0.19155  1.7976224\n",
       "394 -1.2828 1.1237  0.04940  ... 0.7135787 -1.9553 1.8769 -0.23950  0.8609714\n",
       "395 -1.0822 1.1166 -0.08405  ... 0.7141977 -1.9285 2.0766  0.08010  0.8621584\n",
       "396 -2.5429 2.4081 -0.12910  ... 1.0066063 -2.4043 1.5056 -0.12860  1.6121359\n",
       "397 -2.6734 2.4506  0.07725  ... 1.4259974 -4.1238 4.2297 -0.24790  1.7976224\n",
       "398 -2.4111 2.4533 -0.09910  ... 1.1076786 -3.1215 2.2947 -0.14000  1.5025833\n",
       "399 -2.8507 2.4343  0.13105  ... 1.2135140 -2.5112 2.1638 -0.22680  1.7924158\n",
       "400 -0.9340 1.2039  0.01090  ... 0.7135787 -2.1186 1.5632 -0.13970  0.9087400\n",
       "    aT_sd     aT_min aT_maT aT_median y\n",
       "351 0.7808319 0.380  4.098  1.8200    4\n",
       "352 0.7749686 0.127  4.463  1.8350    4\n",
       "353 0.8300253 0.387  5.138  1.9920    4\n",
       "354 0.8351505 0.173  4.458  1.8735    4\n",
       "355 0.7909640 0.436  3.944  1.7570    4\n",
       "356 0.7562042 0.580  3.573  1.6960    4\n",
       "357 0.7120829 0.298  3.895  1.7575    4\n",
       "358 0.8513573 0.397  4.191  1.8180    4\n",
       "359 0.6971337 0.370  3.775  1.9030    4\n",
       "360 0.7296095 0.283  3.813  1.8440    4\n",
       "361 0.8511168 0.446  4.351  1.8600    4\n",
       "362 0.7622031 0.491  3.355  2.1620    4\n",
       "363 0.8526128 0.373  4.351  1.8705    4\n",
       "364 0.6450616 0.233  3.603  1.0730    1\n",
       "365 0.4214891 0.214  2.180  0.9265    1\n",
       "366 0.7439326 0.354  4.156  1.8450    4\n",
       "367 0.4523664 0.376  2.106  1.2830    4\n",
       "368 0.3962710 0.230  2.123  0.8120    1\n",
       "369 0.4517633 0.193  2.380  0.8865    2\n",
       "370 0.7343952 0.489  3.764  1.7520    3\n",
       "371 0.4160549 0.201  2.053  0.8520    2\n",
       "372 0.3846176 0.222  1.752  0.8950    1\n",
       "373 0.4315494 0.478  2.288  1.3220    4\n",
       "374 0.9167571 0.295  4.830  1.9430    4\n",
       "375 0.8012418 0.198  4.290  1.2550    1\n",
       "376 0.5391791 0.294  3.081  1.1770    3\n",
       "377 0.7053254 0.326  3.742  1.5815    3\n",
       "378 0.5131552 0.305  2.091  1.2830    4\n",
       "379 0.4541700 0.262  2.264  0.8270    2\n",
       "380 0.4813814 0.150  2.084  0.7900    2\n",
       "381 0.7254306 0.377  3.348  1.7770    4\n",
       "382 0.7520192 0.400  3.651  1.9180    4\n",
       "383 0.7680118 0.295  3.671  1.7780    4\n",
       "384 0.4517633 0.266  2.407  0.8000    2\n",
       "385 0.4493956 0.164  2.222  0.8120    2\n",
       "386 0.5158915 0.376  2.428  1.5820    4\n",
       "387 0.6825190 0.428  2.988  1.5810    4\n",
       "388 0.4437911 0.266  2.222  0.8410    1\n",
       "389 0.7778120 0.242  4.098  1.9170    4\n",
       "390 0.8489206 0.397  3.963  1.8600    4\n",
       "391 0.4276036 0.285  2.353  0.8930    2\n",
       "392 0.7562042 0.131  4.443  1.1075    1\n",
       "393 0.7133729 0.326  3.651  1.7310    4\n",
       "394 0.4064190 0.054  2.031  0.7900    2\n",
       "395 0.4222442 0.193  2.180  0.7910    2\n",
       "396 0.5853224 0.052  2.517  1.6945    4\n",
       "397 0.9082928 0.212  5.397  1.6595    3\n",
       "398 0.7521618 0.168  3.790  1.4420    3\n",
       "399 0.6828006 0.397  3.197  1.7150    3\n",
       "400 0.3767882 0.170  2.507  0.8120    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputedResultData = mice::complete(imputed_Data,1)\n",
    "tail(imputedResultData, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at distribution actual data and imputed data\n",
    "We will first compare basic statistics and then distributions of the couple of features. In the comparison of statistics between actual and imputed we can observe that the mean and SD for both imputed and actual are almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>actual_ax_mean</th><th scope=col>imputed_ax_mean</th><th scope=col>actual_ax_median</th><th scope=col>imputed_ax_median</th><th scope=col>actual_az_sd</th><th scope=col>imputed_az_sd</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mean</th><td>0.006307909 </td><td>0.005851233 </td><td>-0.001328867</td><td>-0.00214025 </td><td>1.0588650   </td><td>1.0528059   </td></tr>\n",
       "\t<tr><th scope=row>sd</th><td>0.030961085 </td><td>0.031125848 </td><td> 0.059619834</td><td> 0.06011342 </td><td>0.2446782   </td><td>0.2477697   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & actual\\_ax\\_mean & imputed\\_ax\\_mean & actual\\_ax\\_median & imputed\\_ax\\_median & actual\\_az\\_sd & imputed\\_az\\_sd\\\\\n",
       "\\hline\n",
       "\tmean & 0.006307909  & 0.005851233  & -0.001328867 & -0.00214025  & 1.0588650    & 1.0528059   \\\\\n",
       "\tsd & 0.030961085  & 0.031125848  &  0.059619834 &  0.06011342  & 0.2446782    & 0.2477697   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | actual_ax_mean | imputed_ax_mean | actual_ax_median | imputed_ax_median | actual_az_sd | imputed_az_sd |\n",
       "|---|---|---|---|---|---|---|\n",
       "| mean | 0.006307909  | 0.005851233  | -0.001328867 | -0.00214025  | 1.0588650    | 1.0528059    |\n",
       "| sd | 0.030961085  | 0.031125848  |  0.059619834 |  0.06011342  | 0.2446782    | 0.2477697    |\n",
       "\n"
      ],
      "text/plain": [
       "     actual_ax_mean imputed_ax_mean actual_ax_median imputed_ax_median\n",
       "mean 0.006307909    0.005851233     -0.001328867     -0.00214025      \n",
       "sd   0.030961085    0.031125848      0.059619834      0.06011342      \n",
       "     actual_az_sd imputed_az_sd\n",
       "mean 1.0588650    1.0528059    \n",
       "sd   0.2446782    0.2477697    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.frame(actual_ax_mean = c(mean(features$ax_mean), sd(features$ax_mean)) \n",
    "           , imputed_ax_mean = c(mean(imputedResultData$ax_mean), sd(imputedResultData$ax_mean))\n",
    "           , actual_ax_median = c(mean(features$ax_median), sd(features$ax_median)) \n",
    "           , imputed_ax_median = c(mean(imputedResultData$ax_median), sd(imputedResultData$ax_median))\n",
    "           , actual_az_sd = c(mean(features$az_sd), sd(features$az_sd)) \n",
    "           , imputed_az_sd = c(mean(imputedResultData$az_sd), sd(imputedResultData$az_sd))\n",
    "           , row.names = c(\"mean\", \"sd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets look at the distributions in the data. From the distribution below, we can observe that the distributions for actual data and imputed data is almost identical. We can confirm it with the bandwidth in the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"Imputed az_sd\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par(mfrow=c(3,2))\n",
    "plot(density(features$ax_mean), main = \"Actual ax_mean\", type=\"l\", col=\"red\")\n",
    "plot(density(imputedResultData$ax_mean), main = \"Imputed ax_mean\", type=\"l\", col=\"red\")\n",
    "plot(density(features$ax_median), main = \"Actual ax_median\", type=\"l\", col=\"red\")\n",
    "plot(density(imputedResultData$ax_median), main = \"Imputed ax_median\", type=\"l\", col=\"red\")\n",
    "plot(density(features$az_sd), main = \"Actual az_sdn\", type=\"l\", col=\"red\")\n",
    "plot(density(imputedResultData$az_sd), main = \"Imputed az_sd\", type=\"l\", col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a classification model based on actual data and Imputed data\n",
    "\n",
    "In the following data y will be our classification variable. We will build a classification model using basic support vector machine(SVM) with actual and imputed data. No transformation will be done on the data. In the end we will compare the results\n",
    "### Actual Data\n",
    "#### Sample data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create samples of 80:20 ratio\n",
    "features$y = as.factor(features$y)\n",
    "sample = sample(nrow(features) , nrow(features)* 0.8)\n",
    "train = features[sample,]\n",
    "test = features[-sample,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "svm(formula = y ~ ., data = train)\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  C-classification \n",
       " SVM-Kernel:  radial \n",
       "       cost:  1 \n",
       "      gamma:  0.05 \n",
       "\n",
       "Number of Support Vectors:  142\n",
       "\n",
       " ( 47 18 47 30 )\n",
       "\n",
       "\n",
       "Number of Classes:  4 \n",
       "\n",
       "Levels: \n",
       " 1 2 3 4\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(e1071)\n",
    "library(caret)\n",
    "\n",
    "actual.svm.model = svm(y ~., data = train)\n",
    "summary(actual.svm.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate SVM model\n",
    "In the below confusion matrix, we observe the following  \n",
    "1. accuary>NIR indicating model is very good\n",
    "2. Higher accuray and kappa value indicates a very accurate model\n",
    "3. Even the balanced accuracy is close to 1 indicating the model is highly accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  1  2  3  4\n",
       "         1 10  1  0  0\n",
       "         2  0 26  0  0\n",
       "         3  0  0 22  0\n",
       "         4  0  0  3 11\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.9452          \n",
       "                 95% CI : (0.8656, 0.9849)\n",
       "    No Information Rate : 0.3699          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.9234          \n",
       " Mcnemar's Test P-Value : NA              \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: 1 Class: 2 Class: 3 Class: 4\n",
       "Sensitivity            1.0000   0.9630   0.8800   1.0000\n",
       "Specificity            0.9841   1.0000   1.0000   0.9516\n",
       "Pos Pred Value         0.9091   1.0000   1.0000   0.7857\n",
       "Neg Pred Value         1.0000   0.9787   0.9412   1.0000\n",
       "Prevalence             0.1370   0.3699   0.3425   0.1507\n",
       "Detection Rate         0.1370   0.3562   0.3014   0.1507\n",
       "Detection Prevalence   0.1507   0.3562   0.3014   0.1918\n",
       "Balanced Accuracy      0.9921   0.9815   0.9400   0.9758"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(predict(actual.svm.model, test), test$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputed Data\n",
    "#### Sample data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create samples of 80:20 ratio\n",
    "imputedResultData$y = as.factor(imputedResultData$y)\n",
    "sample = sample(nrow(imputedResultData) , nrow(imputedResultData)* 0.8)\n",
    "train = imputedResultData[sample,]\n",
    "test = imputedResultData[-sample,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "svm(formula = y ~ ., data = train)\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  C-classification \n",
       " SVM-Kernel:  radial \n",
       "       cost:  1 \n",
       "      gamma:  0.05 \n",
       "\n",
       "Number of Support Vectors:  167\n",
       "\n",
       " ( 59 47 36 25 )\n",
       "\n",
       "\n",
       "Number of Classes:  4 \n",
       "\n",
       "Levels: \n",
       " 1 2 3 4\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputed.svm.model = svm(y ~., data = train)\n",
    "summary(imputed.svm.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate SVM model\n",
    "In the below confusion matrix, we observe the following  \n",
    "1. accuary>NIR indicating model is very good\n",
    "2. Higher accuray and kappa value indicates a very accurate model\n",
    "3. Even the balanced accuracy is close to 1 indicating the model is highly accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  1  2  3  4\n",
       "         1 15  0  0  0\n",
       "         2  1 21  0  0\n",
       "         3  0  0 17  0\n",
       "         4  0  0  0 26\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.9875          \n",
       "                 95% CI : (0.9323, 0.9997)\n",
       "    No Information Rate : 0.325           \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.9831          \n",
       " Mcnemar's Test P-Value : NA              \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: 1 Class: 2 Class: 3 Class: 4\n",
       "Sensitivity            0.9375   1.0000   1.0000    1.000\n",
       "Specificity            1.0000   0.9831   1.0000    1.000\n",
       "Pos Pred Value         1.0000   0.9545   1.0000    1.000\n",
       "Neg Pred Value         0.9846   1.0000   1.0000    1.000\n",
       "Prevalence             0.2000   0.2625   0.2125    0.325\n",
       "Detection Rate         0.1875   0.2625   0.2125    0.325\n",
       "Detection Prevalence   0.1875   0.2750   0.2125    0.325\n",
       "Balanced Accuracy      0.9688   0.9915   1.0000    1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(predict(imputed.svm.model, test), test$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall results\n",
    "What we saw above and their interpretation is completly subjective. One way to truly validate them is to create random train and test samples multiple times (say 30), build a model, validate the model, capture kappa value. Finally use a simple t-test to see if there is a significant difference.   \n",
    "\n",
    "Null hypotheisis:   \n",
    "H0: there is no significant difference between two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create functions to simplify the process\n",
    "\n",
    "test.function = function(data){\n",
    "    # create samples\n",
    "    sample = sample(nrow(data) , nrow(data)* 0.75)\n",
    "    train = data[sample,]\n",
    "    test = data[-sample,]\n",
    "    \n",
    "    # build model\n",
    "    svm.model = svm(y ~., data = train)\n",
    "    \n",
    "    # get metrics\n",
    "    metrics = confusionMatrix(predict(svm.model, test), test$y)\n",
    "    return(metrics$overall['Accuracy'])\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.978021978021978</li>\n",
       "\t<li>0.978021978021978</li>\n",
       "\t<li>0.978021978021978</li>\n",
       "\t<li>0.945054945054945</li>\n",
       "\t<li>0.989010989010989</li>\n",
       "\t<li>0.967032967032967</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.978021978021978\n",
       "\\item 0.978021978021978\n",
       "\\item 0.978021978021978\n",
       "\\item 0.945054945054945\n",
       "\\item 0.989010989010989\n",
       "\\item 0.967032967032967\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.978021978021978\n",
       "2. 0.978021978021978\n",
       "3. 0.978021978021978\n",
       "4. 0.945054945054945\n",
       "5. 0.989010989010989\n",
       "6. 0.967032967032967\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.9780220 0.9780220 0.9780220 0.9450549 0.9890110 0.9670330"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now lets calculate accuracy with actual data to get 30 results\n",
    "actual.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    actual.results[i] = test.function(features)\n",
    "}\n",
    "head(actual.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.97</li>\n",
       "\t<li>0.95</li>\n",
       "\t<li>0.92</li>\n",
       "\t<li>0.96</li>\n",
       "\t<li>0.92</li>\n",
       "\t<li>0.96</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.97\n",
       "\\item 0.95\n",
       "\\item 0.92\n",
       "\\item 0.96\n",
       "\\item 0.92\n",
       "\\item 0.96\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.97\n",
       "2. 0.95\n",
       "3. 0.92\n",
       "4. 0.96\n",
       "5. 0.92\n",
       "6. 0.96\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.97 0.95 0.92 0.96 0.92 0.96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now lets calculate accuracy with imputed data to get 30 results\n",
    "imputed.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    imputed.results[i] = test.function(imputedResultData)\n",
    "}\n",
    "head(imputed.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-test to test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  actual.results and imputed.results\n",
       "t = 7.9834, df = 194.03, p-value = 1.222e-13\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.01673213 0.02771182\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 0.968022  0.945800 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do a simple t-test to see if there is a difference in accuracy when data is imputed\n",
    "t.test(x= actual.results, y = imputed.results, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above t-test we have set the confidence level at 95%. From the results we can observe that the p-value is less than 0.05 indicating that there is a significant difference in accuracy between actual data and imputed data. From the means we can notics that the average accuracy of actual data is about 96.5% while the accuracy of imputed data y is about 92.5%. There is a variation of 4%. So, does that mean imputing more data results in reducing the accuracy across various models?\n",
    "\n",
    "Why not do a test to compare the results? let's consider 4 other models for that and those will be  \n",
    "1. Random forest\n",
    "2. Decision tree\n",
    "3. KNN\n",
    "4. Naive Bayes\n",
    "\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Actual</th><th scope=col>Imputed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.956044</td><td>0.95    </td></tr>\n",
       "\t<tr><td>1.000000</td><td>0.93    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>0.96    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>0.96    </td></tr>\n",
       "\t<tr><td>1.000000</td><td>0.97    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>0.93    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Actual & Imputed\\\\\n",
       "\\hline\n",
       "\t 0.956044 & 0.95    \\\\\n",
       "\t 1.000000 & 0.93    \\\\\n",
       "\t 0.967033 & 0.96    \\\\\n",
       "\t 0.967033 & 0.96    \\\\\n",
       "\t 1.000000 & 0.97    \\\\\n",
       "\t 0.967033 & 0.93    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Actual | Imputed |\n",
       "|---|---|\n",
       "| 0.956044 | 0.95     |\n",
       "| 1.000000 | 0.93     |\n",
       "| 0.967033 | 0.96     |\n",
       "| 0.967033 | 0.96     |\n",
       "| 1.000000 | 0.97     |\n",
       "| 0.967033 | 0.93     |\n",
       "\n"
      ],
      "text/plain": [
       "  Actual   Imputed\n",
       "1 0.956044 0.95   \n",
       "2 1.000000 0.93   \n",
       "3 0.967033 0.96   \n",
       "4 0.967033 0.96   \n",
       "5 1.000000 0.97   \n",
       "6 0.967033 0.93   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  actual.rf.results and imputed.rf.results\n",
       "t = 11.734, df = 183.2, p-value < 2.2e-16\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.02183138 0.03065654\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 0.976044  0.949800 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(randomForest)\n",
    "\n",
    "# lets create functions to simplify the process\n",
    "\n",
    "test.rf.function = function(data){\n",
    "    # create samples\n",
    "    sample = sample(nrow(data) , nrow(data)* 0.75)\n",
    "    train = data[sample,]\n",
    "    test = data[-sample,]\n",
    "    \n",
    "    # build model\n",
    "    rf.model = randomForest(y ~., data = train)\n",
    "    \n",
    "    # get metrics\n",
    "    metrics = confusionMatrix(predict(rf.model, test), test$y)\n",
    "    return(metrics$overall['Accuracy'])\n",
    "    \n",
    "}\n",
    "\n",
    "# now lets calculate accuracy with actual data to get 30 results\n",
    "actual.rf.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    actual.rf.results[i] = test.rf.function(features)\n",
    "}\n",
    "#head(actual.rf.results)\n",
    "\n",
    "# now lets calculate accuracy with imputed data to get 30 results\n",
    "imputed.rf.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    imputed.rf.results[i] = test.rf.function(imputedResultData)\n",
    "}\n",
    "head(data.frame(Actual = actual.rf.results, Imputed = imputed.rf.results))\n",
    "\n",
    "# Do a simple t-test to see if there is a difference in accuracy when data is imputed\n",
    "t.test(x= actual.rf.results, y = imputed.rf.results, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Actual</th><th scope=col>Imputed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.978022</td><td>0.92    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>0.94    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>0.95    </td></tr>\n",
       "\t<tr><td>0.956044</td><td>0.94    </td></tr>\n",
       "\t<tr><td>0.956044</td><td>0.94    </td></tr>\n",
       "\t<tr><td>0.978022</td><td>0.95    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Actual & Imputed\\\\\n",
       "\\hline\n",
       "\t 0.978022 & 0.92    \\\\\n",
       "\t 0.967033 & 0.94    \\\\\n",
       "\t 0.967033 & 0.95    \\\\\n",
       "\t 0.956044 & 0.94    \\\\\n",
       "\t 0.956044 & 0.94    \\\\\n",
       "\t 0.978022 & 0.95    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Actual | Imputed |\n",
       "|---|---|\n",
       "| 0.978022 | 0.92     |\n",
       "| 0.967033 | 0.94     |\n",
       "| 0.967033 | 0.95     |\n",
       "| 0.956044 | 0.94     |\n",
       "| 0.956044 | 0.94     |\n",
       "| 0.978022 | 0.95     |\n",
       "\n"
      ],
      "text/plain": [
       "  Actual   Imputed\n",
       "1 0.978022 0.92   \n",
       "2 0.967033 0.94   \n",
       "3 0.967033 0.95   \n",
       "4 0.956044 0.94   \n",
       "5 0.956044 0.94   \n",
       "6 0.978022 0.95   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  actual.dt.results and imputed.dt.results\n",
       "t = 16.24, df = 167.94, p-value < 2.2e-16\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.03331888 0.04254046\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "0.9703297 0.9324000 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(rpart)\n",
    "\n",
    "# lets create functions to simplify the process\n",
    "\n",
    "test.dt.function = function(data){\n",
    "    # create samples\n",
    "    sample = sample(nrow(data) , nrow(data)* 0.75)\n",
    "    train = data[sample,]\n",
    "    test = data[-sample,]\n",
    "    \n",
    "    # build model\n",
    "    dt.model = rpart(y ~., data = train, method=\"class\")\n",
    "    \n",
    "    # get metrics\n",
    "    metrics = confusionMatrix(predict(dt.model, test, type=\"class\"), test$y)\n",
    "    return(metrics$overall['Accuracy'])\n",
    "    \n",
    "}\n",
    "\n",
    "# now lets calculate accuracy with actual data to get 30 results\n",
    "actual.dt.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    actual.dt.results[i] = test.dt.function(features)\n",
    "}\n",
    "#head(actual.rf.results)\n",
    "\n",
    "# now lets calculate accuracy with imputed data to get 30 results\n",
    "imputed.dt.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    imputed.dt.results[i] = test.dt.function(imputedResultData)\n",
    "}\n",
    "head(data.frame(Actual = actual.dt.results, Imputed = imputed.dt.results))\n",
    "\n",
    "# Do a simple t-test to see if there is a difference in accuracy when data is imputed\n",
    "t.test(x= actual.dt.results, y = imputed.dt.results, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Actual</th><th scope=col>Imputed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.967033</td><td>0.97    </td></tr>\n",
       "\t<tr><td>1.000000</td><td>0.98    </td></tr>\n",
       "\t<tr><td>0.978022</td><td>0.99    </td></tr>\n",
       "\t<tr><td>0.978022</td><td>1.00    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>1.00    </td></tr>\n",
       "\t<tr><td>0.978022</td><td>1.00    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Actual & Imputed\\\\\n",
       "\\hline\n",
       "\t 0.967033 & 0.97    \\\\\n",
       "\t 1.000000 & 0.98    \\\\\n",
       "\t 0.978022 & 0.99    \\\\\n",
       "\t 0.978022 & 1.00    \\\\\n",
       "\t 0.967033 & 1.00    \\\\\n",
       "\t 0.978022 & 1.00    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Actual | Imputed |\n",
       "|---|---|\n",
       "| 0.967033 | 0.97     |\n",
       "| 1.000000 | 0.98     |\n",
       "| 0.978022 | 0.99     |\n",
       "| 0.978022 | 1.00     |\n",
       "| 0.967033 | 1.00     |\n",
       "| 0.978022 | 1.00     |\n",
       "\n"
      ],
      "text/plain": [
       "  Actual   Imputed\n",
       "1 0.967033 0.97   \n",
       "2 1.000000 0.98   \n",
       "3 0.978022 0.99   \n",
       "4 0.978022 1.00   \n",
       "5 0.967033 1.00   \n",
       "6 0.978022 1.00   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  actual.dt.results and imputed.dt.results\n",
       "t = 3.2151, df = 166.45, p-value = 0.001566\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.002126868 0.008895110\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 0.989011  0.983500 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(class)\n",
    "\n",
    "# lets create functions to simplify the process\n",
    "\n",
    "test.knn.function = function(data){\n",
    "    # create samples\n",
    "    sample = sample(nrow(data) , nrow(data)* 0.75)\n",
    "    train = data[sample,]\n",
    "    test = data[-sample,]\n",
    "    \n",
    "    # build model\n",
    "    knn.model = knn(train,test, cl=train$y, k=5)\n",
    "    \n",
    "    # get metrics\n",
    "    metrics = confusionMatrix(knn.model, test$y)\n",
    "    return(metrics$overall['Accuracy'])\n",
    "    \n",
    "}\n",
    "\n",
    "# now lets calculate accuracy with actual data to get 30 results\n",
    "actual.dt.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    actual.dt.results[i] = test.knn.function(features)\n",
    "}\n",
    "#head(actual.rf.results)\n",
    "\n",
    "# now lets calculate accuracy with imputed data to get 30 results\n",
    "imputed.dt.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    imputed.dt.results[i] = test.knn.function(imputedResultData)\n",
    "}\n",
    "head(data.frame(Actual = actual.dt.results, Imputed = imputed.dt.results))\n",
    "\n",
    "# Do a simple t-test to see if there is a difference in accuracy when data is imputed\n",
    "t.test(x= actual.dt.results, y = imputed.dt.results, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Actual</th><th scope=col>Imputed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.989011</td><td>0.95    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>0.92    </td></tr>\n",
       "\t<tr><td>0.978022</td><td>0.94    </td></tr>\n",
       "\t<tr><td>1.000000</td><td>0.95    </td></tr>\n",
       "\t<tr><td>0.989011</td><td>0.90    </td></tr>\n",
       "\t<tr><td>0.967033</td><td>0.93    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Actual & Imputed\\\\\n",
       "\\hline\n",
       "\t 0.989011 & 0.95    \\\\\n",
       "\t 0.967033 & 0.92    \\\\\n",
       "\t 0.978022 & 0.94    \\\\\n",
       "\t 1.000000 & 0.95    \\\\\n",
       "\t 0.989011 & 0.90    \\\\\n",
       "\t 0.967033 & 0.93    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Actual | Imputed |\n",
       "|---|---|\n",
       "| 0.989011 | 0.95     |\n",
       "| 0.967033 | 0.92     |\n",
       "| 0.978022 | 0.94     |\n",
       "| 1.000000 | 0.95     |\n",
       "| 0.989011 | 0.90     |\n",
       "| 0.967033 | 0.93     |\n",
       "\n"
      ],
      "text/plain": [
       "  Actual   Imputed\n",
       "1 0.989011 0.95   \n",
       "2 0.967033 0.92   \n",
       "3 0.978022 0.94   \n",
       "4 1.000000 0.95   \n",
       "5 0.989011 0.90   \n",
       "6 0.967033 0.93   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  actual.nb.results and imputed.nb.results\n",
       "t = 18.529, df = 174.88, p-value < 2.2e-16\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.04214191 0.05218996\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "0.9740659 0.9269000 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets create functions to simplify the process\n",
    "\n",
    "test.nb.function = function(data){\n",
    "    # create samples\n",
    "    sample = sample(nrow(data) , nrow(data)* 0.75)\n",
    "    train = data[sample,]\n",
    "    test = data[-sample,]\n",
    "    \n",
    "    # build model\n",
    "    nb.model = naiveBayes(y ~., data = train)\n",
    "    \n",
    "    # get metrics\n",
    "    metrics = confusionMatrix(predict(nb.model, test), test$y)\n",
    "    return(metrics$overall['Accuracy'])\n",
    "    \n",
    "}\n",
    "\n",
    "# now lets calculate accuracy with actual data to get 30 results\n",
    "actual.nb.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    actual.nb.results[i] = test.nb.function(features)\n",
    "}\n",
    "#head(actual.rf.results)\n",
    "\n",
    "# now lets calculate accuracy with imputed data to get 30 results\n",
    "imputed.nb.results  = NULL\n",
    "for(i in 1:100) {\n",
    "    imputed.nb.results[i] = test.nb.function(imputedResultData)\n",
    "}\n",
    "head(data.frame(Actual = actual.nb.results, Imputed = imputed.nb.results))\n",
    "\n",
    "# Do a simple t-test to see if there is a difference in accuracy when data is imputed\n",
    "t.test(x= actual.nb.results, y = imputed.nb.results, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "From the above resuls we observe that irrespective of the type of model built, we observed a standard variation in accuracy in the range of 3% - 5% between using actual data and imputed data. In all the cases, actual data helped in building a better model compared to using imputed data for building the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
